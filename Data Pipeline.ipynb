{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Alignment \n",
    "\n",
    "1st part of the data pipeline\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Align the VOC's to the movie screenings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal as ss\n",
    "import math\n",
    "import datetime\n",
    "from dtw import dtw \n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the various csvs\n",
    "\n",
    "#2013 Dataset\n",
    "vocPath = 'Numerical Data/CO2data.csv'\n",
    "co2Df = pd.read_csv(vocPath, usecols = ['Time','CO2'], header = 0, nrows = 74208)\n",
    "movieScreeningsPath = 'Numerical Data/screening_times.csv'\n",
    "movingScreeningsDf = pd.read_csv(movieScreeningsPath, usecols = ['scheduled','movie','filled %'])\n",
    "movieRuntimesPath = 'Numerical Data/movie_runtimes.csv'\n",
    "movieRuntimeDf = pd.read_csv(movieRuntimesPath, usecols = ['movie', 'runtime (mins)', 'effective runtime'])\n",
    "\n",
    "#2015 Dataset\n",
    "starWarsPath = 'Numerical Data/Star Wars-The Force Awakens.csv'\n",
    "starWarsScreeningDf = pd.read_csv(starWarsPath)\n",
    "imOffThenPath = 'Numerical Data/I\\'m Off Then.csv'\n",
    "imOffThenScreeningDf = pd.read_csv(imOffThenPath)\n",
    "helpIShrunkTheTeacherPath = 'Numerical Data/Help, I\\'ve Shrunk The Teacher.csv'\n",
    "helpIShrunkTheTeacherScreeningDf = pd.read_csv(helpIShrunkTheTeacherPath)\n",
    "vocPath = 'Numerical Data/final_data_ppb.csv'\n",
    "cinestar2015Co2Df = pd.read_csv(vocPath, usecols = ['Time', 'CO2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VOC DATAFRAME\n",
    "\n",
    "#VOC timings with datetime object\n",
    "for i in range(0,co2Df.shape[0]):\n",
    "    vocTime = co2Df.loc[i]['Time']\n",
    "    vocTime = vocTime[1:len(vocTime)-1]\n",
    "    date = datetime.datetime.strptime(vocTime, \"%m/%d/%Y %H:%M:%S\")\n",
    "    co2Df.at[i,'Time'] = date.strftime('%d-%m-%Y %H:%M')\n",
    "\n",
    "for i in range(0, cinestar2015Co2Df.shape[0]):\n",
    "    vocTime = cinestar2015Co2Df.loc[i]['Time']\n",
    "    date = datetime.datetime.strptime(vocTime, \"%d/%m/%Y %H:%M\")\n",
    "    cinestar2015Co2Df.at[i,'Time'] = date.strftime('%d-%m-%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388.595"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(co2Df['CO2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOVIE SCREENINGS\n",
    "#change scheduled time into standardised format\n",
    "\n",
    "#2013\n",
    "for i in range(0,movingScreeningsDf.shape[0]):\n",
    "    scheduledTime = movingScreeningsDf.loc[i]['scheduled']\n",
    "    scheduledTimeObj = datetime.datetime.strptime(scheduledTime, \"%d/%m/%Y %H:%M\")\n",
    "    scheduledTime = scheduledTimeObj.strftime('%d-%m-%Y %H:%M')\n",
    "    movingScreeningsDf.at[i,'scheduled'] = scheduledTime\n",
    "    \n",
    "#2015 Star Wars\n",
    "for i in range(0, starWarsScreeningDf.shape[0]):\n",
    "    beginTime = starWarsScreeningDf.loc[i]['Start']\n",
    "    beginTimeObj = datetime.datetime.strptime(beginTime,  \"%d/%m/%Y %H:%M\")\n",
    "    beginTime = beginTimeObj.strftime('%d-%m-%Y %H:%M')\n",
    "    starWarsScreeningDf.at[i,'Start'] = beginTime\n",
    "\n",
    "#2015 I'm Off Then\n",
    "for i in range(0, imOffThenScreeningDf.shape[0]):\n",
    "    beginTime = imOffThenScreeningDf.loc[i]['Start']\n",
    "    beginTimeObj = datetime.datetime.strptime(beginTime,  \"%d/%m/%Y %H:%M\")\n",
    "    beginTime = beginTimeObj.strftime('%d-%m-%Y %H:%M')\n",
    "    imOffThenScreeningDf.at[i,'Start'] = beginTime\n",
    "    \n",
    "#2015 Help, I Shrunk The Teacher\n",
    "for i in range(0, helpIShrunkTheTeacherScreeningDf.shape[0]):\n",
    "    beginTime = helpIShrunkTheTeacherScreeningDf.loc[i]['Start']\n",
    "    beginTimeObj = datetime.datetime.strptime(beginTime,  \"%d/%m/%Y %H:%M\")\n",
    "    beginTime = beginTimeObj.strftime('%d-%m-%Y %H:%M')\n",
    "    helpIShrunkTheTeacherScreeningDf.at[i,'Start'] = beginTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Detection Algorithm\n",
    "\n",
    "1. Align the VOC frames using the scheduled times and add some tolerance at the end \n",
    "2. Go to the scheduled end within the voc frame\n",
    "3. check for the last peak/last crest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#2013 Alignment \n",
    "\n",
    "vocList = list()\n",
    "scheduledTimeList = [x for x in movingScreeningsDf.loc[:]['scheduled']]\n",
    "movieScreeningList = [x for x in movingScreeningsDf.loc[:]['movie']]\n",
    "movieList = [x for x in movieRuntimeDf.loc[:]['movie']]\n",
    "vocTimeList = [x for x in co2Df.loc[:]['Time']]\n",
    "filledPercentageList = [x for x in movingScreeningsDf.loc[:]['filled %']]\n",
    "matchedMovieList = list()\n",
    "timeList = list()\n",
    "\n",
    "gradThreshold = -0.045\n",
    "\n",
    "skipSecondInterval = False\n",
    "originalVOCFrames = list()\n",
    "\n",
    "for vocTime in vocTimeList:\n",
    "    \n",
    "    try:\n",
    "        timeIndex = scheduledTimeList.index(vocTime)\n",
    "    except:\n",
    "        continue \n",
    "        \n",
    "    if vocTime not in timeList:\n",
    "\n",
    "        if filledPercentageList[timeIndex] > 10: #only use well filled movies\n",
    "\n",
    "            #Preliminary Alignment \n",
    "            movieMatched = movieScreeningList[timeIndex]    #find matched movie\n",
    "            try:\n",
    "                movieIndex = movieList.index(movieMatched)      #find runtime of matched movie\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "            runtime = movieRuntimeDf.loc[movieIndex]['runtime (mins)']\n",
    "            effectiveRuntime = (runtime + 50) * 2 #tolerance added is 15mins and then multiplied by 2 to get the number of 30s intervals\n",
    "            vocIndex = vocTimeList.index(vocTime)\n",
    "            vocEndIndex = vocIndex + effectiveRuntime\n",
    "            vocWindow = co2Df.loc[vocIndex:vocEndIndex][:]\n",
    "            originalVocFrame = co2Df.loc[vocIndex:vocEndIndex][:]\n",
    "\n",
    "            #Delta Gradient Alignment \n",
    "            peakList = list()\n",
    "            peakTimeList = list()\n",
    "            normalisedPeakList = list()\n",
    "            #find_peaks returns the index values of the peaks within the VOC frame \n",
    "            peaks = ss.find_peaks(vocWindow[:]['CO2'].values)\n",
    "            #Using the index values find the actual values of the peaks \n",
    "            if len(peaks[0]) != 0:\n",
    "                for peakIndex in peaks[0]:\n",
    "                    peakList.append(vocWindow[:]['CO2'].values[peakIndex])\n",
    "\n",
    "                #normalise the peaks (divide by highest VOC value)\n",
    "                maxPeak = max(peakList)\n",
    "                for peakValue in peakList:\n",
    "                    normalisedPeakList.append(peakValue/maxPeak) \n",
    "\n",
    "                #calculate the gradient and distance between peaks\n",
    "                #the gradientList and distanceList for vocFrame\n",
    "                gradientList = list()\n",
    "                distanceList = list()\n",
    "                for peakIndex in range(1, len(normalisedPeakList)):\n",
    "                    prevPeak = normalisedPeakList[peakIndex-1]\n",
    "                    currPeak = normalisedPeakList[peakIndex]\n",
    "                    grad = currPeak - prevPeak\n",
    "                    dist = math.sqrt((currPeak - prevPeak)**2 + 1)\n",
    "                    gradientList.append(grad)\n",
    "                    distanceList.append(dist)\n",
    "\n",
    "                #apply constraints to trim the voc window\n",
    "                frontIndex = round(len(gradientList)*0.8) #only check the last 25% of the voc window for the delta constraint\n",
    "                vocGradWindow = gradientList[frontIndex:]\n",
    "\n",
    "                if min(vocGradWindow) > gradThreshold:\n",
    "\n",
    "                    #if the min gradient in the frame is larger than the threshold then just cut off the last peak\n",
    "                    lastPeakIndex = list(vocWindow[:]['CO2'].values).index(peakList[-1])\n",
    "                    #find first index from taking off the effective runtime\n",
    "                    movieIndex = movieList.index(movieMatched)\n",
    "                    effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "                    firstIndex = lastPeakIndex - effectiveRuntime \n",
    "                    vocWindow = vocWindow[firstIndex:lastPeakIndex][:]\n",
    "                    vocList.append(vocWindow)\n",
    "                    timeList.append(vocTime)\n",
    "                    matchedMovieList.append(movieMatched)\n",
    "                    originalVOCFrames.append(originalVocFrame)\n",
    "\n",
    "                else: \n",
    "\n",
    "                    #if min gradient in frame is less than threshold then cut off the peak that starts that gradient\n",
    "                    #find the first grad that is lower than the threshold\n",
    "\n",
    "                    for grad in vocGradWindow:\n",
    "                        if grad < gradThreshold:\n",
    "                            gradIndex = gradientList.index(grad)\n",
    "                            associatedPeak = peakList[gradIndex]\n",
    "                            endIndex = list(vocWindow[:]['CO2'].values).index(associatedPeak)\n",
    "\n",
    "                            movieIndex = movieList.index(movieMatched)\n",
    "                            effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "                            firstIndex = endIndex - effectiveRuntime\n",
    "\n",
    "                            if firstIndex > 0: #positive index\n",
    "\n",
    "                                vocWindow = vocWindow[firstIndex:endIndex][:]\n",
    "                                vocList.append(vocWindow)\n",
    "                                timeList.append(vocTime)\n",
    "                                matchedMovieList.append(movieMatched)\n",
    "                                originalVOCFrames.append(originalVocFrame) \n",
    "                                break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015 Star Wars Alignment  \n",
    "\n",
    "vocStarWars = list()\n",
    "scheduledTimeStarWars = [x for x in starWarsScreeningDf.loc[:]['Start']]\n",
    "vocTimeList = [x for x in cinestar2015Co2Df.loc[:]['Time']]\n",
    "filledPercentageStarWars = [x for x in starWarsScreeningDf.loc[:]['filled %']]\n",
    "movieList = [x for x in movieRuntimeDf.loc[:]['movie']]\n",
    "timeListStarWars = list()\n",
    "\n",
    "gradThreshold = -0.045\n",
    "\n",
    "skipSecondInterval = False\n",
    "\n",
    "for vocTime in vocTimeList:\n",
    "    try:\n",
    "        timeIndex = scheduledTimeStarWars.index(vocTime)\n",
    "    except:\n",
    "        continue \n",
    "        \n",
    "    if vocTime not in timeListStarWars:\n",
    "\n",
    "        if filledPercentageStarWars[timeIndex] > 10: #only use well filled movies\n",
    "            #Preliminary Alignment \n",
    "            movieIndex = movieList.index('Star Wars-The Force Awakens')\n",
    "            runtime = movieRuntimeDf.loc[movieIndex]['runtime (mins)']\n",
    "            effectiveRuntime = (runtime + 50) * 2 #tolerance added is 15mins and then multiplied by 2 to get the number of 30s intervals\n",
    "            vocIndex = vocTimeList.index(vocTime)\n",
    "            vocEndIndex = vocIndex + effectiveRuntime\n",
    "            vocWindow = cinestar2015Co2Df.loc[vocIndex:vocEndIndex][:]\n",
    "            originalVocFrame = cinestar2015Co2Df.loc[vocIndex:vocEndIndex][:]\n",
    "\n",
    "            #Delta Gradient Alignment \n",
    "            peakList = list()\n",
    "            peakTimeList = list()\n",
    "            normalisedPeakList = list()\n",
    "            #find_peaks returns the index values of the peaks within the VOC frame \n",
    "            peaks = ss.find_peaks(vocWindow[:]['CO2'].values)\n",
    "            #Using the index values find the actual values of the peaks \n",
    "            if len(peaks[0]) != 0:\n",
    "                for peakIndex in peaks[0]:\n",
    "                    peakList.append(vocWindow[:]['CO2'].values[peakIndex])\n",
    "\n",
    "                #normalise the peaks (divide by highest VOC value)\n",
    "                maxPeak = max(peakList)\n",
    "                for peakValue in peakList:\n",
    "                    normalisedPeakList.append(peakValue/maxPeak) \n",
    "\n",
    "                #calculate the gradient and distance between peaks\n",
    "                #the gradientList and distanceList for vocFrame\n",
    "                gradientList = list()\n",
    "                distanceList = list()\n",
    "                for peakIndex in range(1, len(normalisedPeakList)):\n",
    "                    prevPeak = normalisedPeakList[peakIndex-1]\n",
    "                    currPeak = normalisedPeakList[peakIndex]\n",
    "                    grad = currPeak - prevPeak\n",
    "                    dist = math.sqrt((currPeak - prevPeak)**2 + 1)\n",
    "                    gradientList.append(grad)\n",
    "                    distanceList.append(dist)\n",
    "\n",
    "                #apply constraints to trim the voc window\n",
    "                frontIndex = round(len(gradientList)*0.8) #only check the last 25% of the voc window for the delta constraint\n",
    "                vocGradWindow = gradientList[frontIndex:]\n",
    "\n",
    "                if min(vocGradWindow) > gradThreshold:\n",
    "\n",
    "                    #if the min gradient in the frame is larger than the threshold then just cut off the last peak\n",
    "                    lastPeakIndex = list(vocWindow[:]['CO2'].values).index(peakList[-1])\n",
    "                    #find first index from taking off the effective runtime\n",
    "                    movieIndex = movieList.index('Star Wars-The Force Awakens')\n",
    "                    effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "                    firstIndex = lastPeakIndex - effectiveRuntime\n",
    "                    vocWindow = vocWindow[firstIndex:lastPeakIndex][:]\n",
    "                    vocStarWars.append(vocWindow)\n",
    "                    timeListStarWars.append(vocTime)\n",
    "                    timeList.append(vocTime)\n",
    "                    originalVOCFrames.append(originalVocFrame)\n",
    "\n",
    "                else: \n",
    "\n",
    "\n",
    "                    for grad in vocGradWindow:\n",
    "                        if grad < gradThreshold:\n",
    "                            gradIndex = gradientList.index(grad)\n",
    "                            associatedPeak = peakList[gradIndex]\n",
    "                            endIndex = list(vocWindow[:]['CO2'].values).index(associatedPeak)\n",
    "\n",
    "                            movieIndex = movieList.index('Star Wars-The Force Awakens')\n",
    "                            effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "                            firstIndex = endIndex - effectiveRuntime\n",
    "\n",
    "                            if firstIndex > 0: #positive index\n",
    "\n",
    "                                vocWindow = vocWindow[firstIndex:endIndex][:]\n",
    "                                vocStarWars.append(vocWindow)\n",
    "                                timeListStarWars.append(vocTime)\n",
    "                                timeList.append(vocTime)\n",
    "                                originalVOCFrames.append(originalVocFrame)  \n",
    "                                break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015 I'm Off Then Alignment\n",
    "\n",
    "vocImOffThen = list()\n",
    "vocTimeList = [x for x in cinestar2015Co2Df.loc[:]['Time']]\n",
    "scheduledTimeImOffThen = [x for x in imOffThenScreeningDf.loc[:]['Start']]\n",
    "filledPercentageImOffThen = [x for x in imOffThenScreeningDf.loc[:]['filled %']]\n",
    "timeListImOffThen = list()\n",
    "gradThreshold = -0.045\n",
    "\n",
    "skipSecondInterval = False\n",
    "\n",
    "for vocTime in vocTimeList:\n",
    "    try:\n",
    "        timeIndex = scheduledTimeImOffThen.index(vocTime)\n",
    "    except:\n",
    "        continue \n",
    "\n",
    "    if vocTime not in timeListImOffThen:\n",
    "        if filledPercentageImOffThen[timeIndex] > 10: #only use well filled movies\n",
    "            #Preliminary Alignment \n",
    "            movieIndex = movieList.index('I\\'m Off Then')\n",
    "            runtime = movieRuntimeDf.loc[movieIndex]['runtime (mins)']\n",
    "            effectiveRuntime = (runtime + 50) * 2 #tolerance added is 15mins and then multiplied by 2 to get the number of 30s intervals\n",
    "            vocIndex = vocTimeList.index(vocTime)\n",
    "            vocEndIndex = vocIndex + effectiveRuntime\n",
    "            vocWindow = cinestar2015Co2Df.loc[vocIndex:vocEndIndex][:]\n",
    "            originalVocFrame = cinestar2015Co2Df.loc[vocIndex:vocEndIndex][:]\n",
    "\n",
    "            #Delta Gradient Alignment \n",
    "            peakList = list()\n",
    "            peakTimeList = list()\n",
    "            normalisedPeakList = list()\n",
    "            #find_peaks returns the index values of the peaks within the VOC frame \n",
    "            peaks = ss.find_peaks(vocWindow[:]['CO2'].values)\n",
    "            #Using the index values find the actual values of the peaks \n",
    "            if len(peaks[0]) != 0:\n",
    "                for peakIndex in peaks[0]:\n",
    "                    peakList.append(vocWindow[:]['CO2'].values[peakIndex])\n",
    "\n",
    "                #normalise the peaks (divide by highest VOC value)\n",
    "                maxPeak = max(peakList)\n",
    "                for peakValue in peakList:\n",
    "                    normalisedPeakList.append(peakValue/maxPeak) \n",
    "\n",
    "                #calculate the gradient and distance between peaks\n",
    "                #the gradientList and distanceList for vocFrame\n",
    "                gradientList = list()\n",
    "                distanceList = list()\n",
    "                for peakIndex in range(1, len(normalisedPeakList)):\n",
    "                    prevPeak = normalisedPeakList[peakIndex-1]\n",
    "                    currPeak = normalisedPeakList[peakIndex]\n",
    "                    grad = currPeak - prevPeak\n",
    "                    dist = math.sqrt((currPeak - prevPeak)**2 + 1)\n",
    "                    gradientList.append(grad)\n",
    "                    distanceList.append(dist)\n",
    "\n",
    "                #apply constraints to trim the voc window\n",
    "                frontIndex = round(len(gradientList)*0.8) #only check the last 25% of the voc window for the delta constraint\n",
    "                vocGradWindow = gradientList[frontIndex:]\n",
    "\n",
    "                if min(vocGradWindow) > gradThreshold:\n",
    "\n",
    "                    #if the min gradient in the frame is larger than the threshold then just cut off the last peak\n",
    "                    lastPeakIndex = list(vocWindow[:]['CO2'].values).index(peakList[-1])\n",
    "                    #find first index from taking off the effective runtime\n",
    "                    movieIndex = movieList.index('I\\'m Off Then')\n",
    "                    effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "                    firstIndex = lastPeakIndex - effectiveRuntime\n",
    "                    vocWindow = vocWindow[firstIndex:lastPeakIndex][:]\n",
    "\n",
    "                    vocImOffThen.append(vocWindow)\n",
    "                    timeListImOffThen.append(vocTime)\n",
    "                    timeList.append(vocTime)\n",
    "                    originalVOCFrames.append(originalVocFrame)\n",
    "\n",
    "                else: \n",
    "\n",
    "                    #if min gradient in frame is less than threshold then cut off the peak that starts that gradient\n",
    "                    #find the first grad that is lower than the threshold\n",
    "\n",
    "                    for grad in vocGradWindow:\n",
    "                        if grad < gradThreshold:\n",
    "                            gradIndex = gradientList.index(grad)\n",
    "                            associatedPeak = peakList[gradIndex]\n",
    "                            endIndex = list(vocWindow[:]['CO2'].values).index(associatedPeak)\n",
    "\n",
    "                            movieIndex = movieList.index('I\\'m Off Then')\n",
    "                            effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "                            firstIndex = endIndex - effectiveRuntime\n",
    "\n",
    "                            if firstIndex > 0: #positive index\n",
    "                                vocWindow = vocWindow[firstIndex:endIndex][:]\n",
    "\n",
    "                                vocImOffThen.append(vocWindow)\n",
    "\n",
    "                                timeListImOffThen.append(vocTime)\n",
    "                                timeList.append(vocTime)\n",
    "                                originalVOCFrames.append(originalVocFrame)\n",
    "\n",
    "                                break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015 Help I Shrunk The Teacher\n",
    "\n",
    "vocHelpIShrunk = list()\n",
    "vocTimeList = [x for x in cinestar2015Co2Df.loc[:]['Time']]\n",
    "scheduledTimeHelpIShrunk = [x for x in helpIShrunkTheTeacherScreeningDf.loc[:]['Start']]\n",
    "filledPercentageHelpIShrunk = [x for x in helpIShrunkTheTeacherScreeningDf.loc[:]['filled %']]\n",
    "timeListHelpIShrunk = list()\n",
    "gradThreshold = -0.045\n",
    "\n",
    "skipSecondInterval = False\n",
    "\n",
    "for vocTime in vocTimeList:\n",
    "    try:\n",
    "        timeIndex = scheduledTimeHelpIShrunk.index(vocTime)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    if vocTime not in timeListHelpIShrunk:\n",
    "\n",
    "        if filledPercentageHelpIShrunk[timeIndex] > 10: #only use well filled movies\n",
    "            #Preliminary Alignment \n",
    "            movieIndex = movieList.index('Help, I\\'ve Shrunk My Teacher')\n",
    "            runtime = movieRuntimeDf.loc[movieIndex]['runtime (mins)']\n",
    "            effectiveRuntime = (runtime + 50) * 2 #tolerance added is 15mins and then multiplied by 2 to get the number of 30s intervals\n",
    "            vocIndex = vocTimeList.index(vocTime)\n",
    "            vocEndIndex = vocIndex + effectiveRuntime\n",
    "            vocWindow = cinestar2015Co2Df.loc[vocIndex:vocEndIndex][:]\n",
    "            originalVocFrame = cinestar2015Co2Df.loc[vocIndex:vocEndIndex][:]\n",
    "\n",
    "\n",
    "            #Delta Gradient Alignment \n",
    "            peakList = list()\n",
    "            peakTimeList = list()\n",
    "            normalisedPeakList = list()\n",
    "            #find_peaks returns the index values of the peaks within the VOC frame \n",
    "            peaks = ss.find_peaks(vocWindow[:]['CO2'].values)\n",
    "            #Using the index values find the actual values of the peaks \n",
    "            if len(peaks[0]) != 0:\n",
    "                for peakIndex in peaks[0]:\n",
    "                    peakList.append(vocWindow[:]['CO2'].values[peakIndex])\n",
    "\n",
    "                #normalise the peaks (divide by highest VOC value)\n",
    "                maxPeak = max(peakList)\n",
    "                for peakValue in peakList:\n",
    "                    normalisedPeakList.append(peakValue/maxPeak) \n",
    "\n",
    "                #calculate the gradient and distance between peaks\n",
    "                #the gradientList and distanceList for vocFrame\n",
    "                gradientList = list()\n",
    "                distanceList = list()\n",
    "                for peakIndex in range(1, len(normalisedPeakList)):\n",
    "                    prevPeak = normalisedPeakList[peakIndex-1]\n",
    "                    currPeak = normalisedPeakList[peakIndex]\n",
    "                    grad = currPeak - prevPeak\n",
    "                    dist = math.sqrt((currPeak - prevPeak)**2 + 1)\n",
    "                    gradientList.append(grad)\n",
    "                    distanceList.append(dist)\n",
    "\n",
    "                #apply constraints to trim the voc window\n",
    "                frontIndex = round(len(gradientList)*0.8) #only check the last 25% of the voc window for the delta constraint\n",
    "                vocGradWindow = gradientList[frontIndex:]\n",
    "\n",
    "                if min(vocGradWindow) > gradThreshold:\n",
    "\n",
    "                    #if the min gradient in the frame is larger than the threshold then just cut off the last peak\n",
    "                    lastPeakIndex = list(vocWindow[:]['CO2'].values).index(peakList[-1])\n",
    "                    #find first index from taking off the effective runtime\n",
    "                    movieIndex = movieList.index('Help, I\\'ve Shrunk My Teacher')\n",
    "                    effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "                    firstIndex = lastPeakIndex - effectiveRuntime\n",
    "                    vocWindow = vocWindow[firstIndex:lastPeakIndex][:]\n",
    "                    vocHelpIShrunk.append(vocWindow)\n",
    "                    timeListHelpIShrunk.append(vocTime)\n",
    "                    timeList.append(vocTime)\n",
    "                    originalVOCFrames.append(originalVocFrame)\n",
    "\n",
    "                else: \n",
    "\n",
    "\n",
    "                    #if min gradient in frame is less than threshold then cut off the peak that starts that gradient\n",
    "                    #find the first grad that is lower than the threshold\n",
    "\n",
    "                    for grad in vocGradWindow:\n",
    "                        if grad < gradThreshold:\n",
    "                            gradIndex = gradientList.index(grad)\n",
    "                            associatedPeak = peakList[gradIndex]\n",
    "                            endIndex = list(vocWindow[:]['CO2'].values).index(associatedPeak)\n",
    "\n",
    "                            movieIndex = movieList.index('Help, I\\'ve Shrunk My Teacher')\n",
    "                            effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "                            firstIndex = endIndex - effectiveRuntime\n",
    "\n",
    "                            if firstIndex > 0: #positive index\n",
    "\n",
    "                                vocWindow = vocWindow[firstIndex:endIndex][:]\n",
    "                                vocHelpIShrunk.append(vocWindow)\n",
    "                                timeListHelpIShrunk.append(vocTime)\n",
    "                                timeList.append(vocTime)\n",
    "                                originalVOCFrames.append(originalVocFrame)\n",
    "                                break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Editting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015 Manual Editting\n",
    "#VOC Screenings to be manually editted after inspection\n",
    "\n",
    "#Help I Shrunk 27-12-2015 11:30\n",
    "#Help I Shrunk 30-12-2015 11:30\n",
    "#Help I Shrunk 02-01-2016 11:30\n",
    "#Help I Shrunk 03-01-2016 11:30\n",
    "\n",
    "vocTimeList = [x for x in cinestar2015Co2Df.loc[:]['Time']]\n",
    "vocHelpIShrunkAdjusted = copy.deepcopy(vocHelpIShrunk)\n",
    "\n",
    "errorDates = ['27-12-2015 11:30', '30-12-2015 11:30', '02-01-2016 11:30', '03-01-2016 11:30']\n",
    "for errorDate in errorDates:\n",
    "    errorIndex = timeList.index(errorDate)\n",
    "    index = timeListHelpIShrunk.index(errorDate)\n",
    "    vocFrame = originalVOCFrames[errorIndex]\n",
    "    if errorDate == '27-12-2015 11:30':\n",
    "        endOfMovie = '27-12-2015 13:30'\n",
    "        movieIndex = movieList.index('Help, I\\'ve Shrunk My Teacher')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocHelpIShrunkAdjusted[index] = vocWindow\n",
    "    \n",
    "    elif errorDate == '30-12-2015 11:30':\n",
    "        endOfMovie = '30-12-2015 13:26'\n",
    "        movieIndex = movieList.index('Help, I\\'ve Shrunk My Teacher')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocHelpIShrunkAdjusted[index] = vocWindow\n",
    "\n",
    "    elif errorDate == '02-01-2016 11:30':\n",
    "        endOfMovie = '02-01-2016 13:23'\n",
    "        movieIndex = movieList.index('Help, I\\'ve Shrunk My Teacher')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime + 1\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocHelpIShrunkAdjusted[index] = vocWindow\n",
    "        \n",
    "    elif errorDate == '03-01-2016 11:30':\n",
    "        endOfMovie = '03-01-2016 13:23'\n",
    "        movieIndex = movieList.index('Help, I\\'ve Shrunk My Teacher')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocHelpIShrunkAdjusted[index] = vocWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015 Manual Editting\n",
    "#VOC Screenings to be manually editted to after inspection\n",
    "\n",
    "#I'm Off Then 27-12-2015 20:00\n",
    "#I'm Off Then 30-12-2015 20:00\n",
    "#I'm Off Then 31-12-2015 20:00\n",
    "#I'm Off Then 02-01-2016 17:30\n",
    "#I'm Off Then 02-01-2016 20:00\n",
    "#I'm Off Then 03-01-2016 17:30\n",
    "vocTimeList = [x for x in cinestar2015Co2Df.loc[:]['Time']]\n",
    "\n",
    "vocImOffThenAdjusted = copy.deepcopy(vocImOffThen)\n",
    "\n",
    "errorDates = ['27-12-2015 20:00', '30-12-2015 20:00', '31-12-2015 20:00', '02-01-2016 17:30','02-01-2016 20:00','03-01-2016 17:30']\n",
    "for errorDate in errorDates:\n",
    "    errorIndex = timeList.index(errorDate)\n",
    "    index = timeListImOffThen.index(errorDate)\n",
    "    vocFrame = originalVOCFrames[errorIndex]\n",
    "    if errorDate == '27-12-2015 20:00':\n",
    "        endOfMovie = '27-12-2015 21:54'\n",
    "        movieIndex = movieList.index('I\\'m Off Then')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocImOffThenAdjusted[index] = vocWindow\n",
    "        \n",
    "    elif errorDate == '30-12-2015 20:00':\n",
    "        endOfMovie = '30-12-2015 21:52'\n",
    "        movieIndex = movieList.index('I\\'m Off Then')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocImOffThenAdjusted[index] = vocWindow\n",
    "        \n",
    "    elif errorDate == '31-12-2015 20:00':\n",
    "        endOfMovie = '31-12-2015 21:53'\n",
    "        movieIndex = movieList.index('I\\'m Off Then')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocImOffThenAdjusted[index] = vocWindow\n",
    "        \n",
    "    elif errorDate == '02-01-2016 17:30':\n",
    "        endOfMovie = '02-01-2016 19:22'\n",
    "        movieIndex = movieList.index('I\\'m Off Then')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocImOffThenAdjusted[index] = vocWindow\n",
    "    \n",
    "    elif errorDate == '02-01-2016 20:00':\n",
    "        endOfMovie = '02-01-2016 21:53'\n",
    "        movieIndex = movieList.index('I\\'m Off Then')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocImOffThenAdjusted[index] = vocWindow\n",
    "\n",
    "    elif errorDate == '03-01-2016 17:30':\n",
    "        endOfMovie = '03-01-2016 19:17'\n",
    "        movieIndex = movieList.index('I\\'m Off Then')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocImOffThenAdjusted[index] = vocWindow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2013 Manual Editting\n",
    "#VOC Screenings to be manually editted to after inspection\n",
    "\n",
    "#The Hunger Games: Catching Fire 27-12-2013 13:15\n",
    "#Buddy 29-12-2013 19:30\n",
    "#Walter Mitty 02-01-2014 17:15\n",
    "#The Hunger Games: Catching Fire 05-01-2014 13:45\n",
    "#Walter Mitty 05-01-2014 17:15\n",
    "#The Hunger Games: Catching Fire 07-01-2014 13:45\n",
    "#Paranormal Activity 09-01-2014 20:35\n",
    "#Hobbit 2 10-01-2014 16:30\n",
    "#Paranormal Activity 10-01-2014 22:35\n",
    "errorList = ['27-12-2013 13:15', '29-12-2013 19:30', '02-01-2014 17:15', '05-01-2014 13:45',\n",
    "             '05-01-2014 17:15', '07-01-2014 13:45', '09-01-2014 20:35', '10-01-2014 16:30', \n",
    "             '10-01-2014 22:35']\n",
    "adjustedVOCList = copy.deepcopy(vocList)\n",
    "\n",
    "for errorDate in errorList: \n",
    "    errorIndex = timeList.index(errorDate)\n",
    "    matchedMovie = matchedMovieList[errorIndex]\n",
    "    vocFrame = originalVOCFrames[errorIndex]\n",
    "    \n",
    "    if errorDate == '27-12-2013 13:15':\n",
    "        endOfMovie = '27-12-2013 15:59' \n",
    "        movieIndex = movieList.index(matchedMovie)\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        adjustedVOCList[errorIndex] = vocWindow\n",
    "\n",
    "    elif errorDate == '29-12-2013 19:30':\n",
    "        endOfMovie = '29-12-2013 21:28' \n",
    "        movieIndex = movieList.index(matchedMovie)\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        adjustedVOCList[errorIndex] = vocWindow  \n",
    "\n",
    "    elif errorDate == '02-01-2014 17:15':\n",
    "        endOfMovie = '02-01-2014 19:21' \n",
    "        movieIndex = movieList.index(matchedMovie)\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        adjustedVOCList[errorIndex] = vocWindow  \n",
    "\n",
    "    elif errorDate == '05-01-2014 13:45':\n",
    "        endOfMovie = '05-01-2014 16:21' \n",
    "        movieIndex = movieList.index(matchedMovie)\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        adjustedVOCList[errorIndex] = vocWindow  \n",
    "        \n",
    "    elif errorDate == '05-01-2014 17:15':\n",
    "        endOfMovie = '05-01-2014 19:21' \n",
    "        movieIndex = movieList.index(matchedMovie)\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        adjustedVOCList[errorIndex] = vocWindow  \n",
    "\n",
    "    elif errorDate == '07-01-2014 13:45':\n",
    "        endOfMovie = '07-01-2014 16:10' \n",
    "        movieIndex = movieList.index(matchedMovie)\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime \n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        adjustedVOCList[errorIndex] = vocWindow  \n",
    "        \n",
    "    elif errorDate == '09-01-2014 20:35':\n",
    "        endOfMovie = '09-01-2014 22:28'\n",
    "        movieIndex = movieList.index(matchedMovie)\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        adjustedVOCList[errorIndex] = vocWindow  \n",
    "\n",
    "    elif errorDate == '10-01-2014 16:30':\n",
    "        endOfMovie = '10-01-2014 19:50'\n",
    "        movieIndex = movieList.index(matchedMovie)\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        adjustedVOCList[errorIndex] = vocWindow  \n",
    "        \n",
    "    elif errorDate == '10-01-2014 22:35':\n",
    "        endOfMovie = '11-01-2014 00:25'\n",
    "        movieIndex = movieList.index(matchedMovie)\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        adjustedVOCList[errorIndex] = vocWindow  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015 Manual Editting\n",
    "#VOC Screenings to be manually editted to after inspection\n",
    "\n",
    "#Star Wars-A Force Awakens 22-12-2015 22:30\n",
    "#Star Wars-A Force Awakens 28-12-2015 22:30\n",
    "#Star Wars-A Force Awakens 29-12-2015 22:30\n",
    "\n",
    "vocTimeList = [x for x in cinestar2015Co2Df.loc[:]['Time']]\n",
    "vocStarWarsAdjusted = copy.deepcopy(vocStarWars)\n",
    "\n",
    "errorDates = ['22-12-2015 22:30', '28-12-2015 22:30', '29-12-2015 22:30']\n",
    "for errorDate in errorDates:\n",
    "    errorIndex = timeList.index(errorDate)\n",
    "    index = timeListStarWars.index(errorDate)\n",
    "    vocFrame = originalVOCFrames[errorIndex]\n",
    "    if errorDate == '22-12-2015 22:30':\n",
    "        endOfMovie = '23-12-2015 00:55'\n",
    "        movieIndex = movieList.index('Star Wars-The Force Awakens')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocStarWarsAdjusted[index] = vocWindow\n",
    "    elif errorDate == '28-12-2015 22:30':\n",
    "        endOfMovie = '29-12-2015 00:59'\n",
    "        movieIndex = movieList.index('Star Wars-The Force Awakens')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocStarWarsAdjusted[index] = vocWindow\n",
    "    elif errorDate == '29-12-2015 22:30':\n",
    "        endOfMovie = '30-12-2015 01:15'\n",
    "        movieIndex = movieList.index('Star Wars-The Force Awakens')\n",
    "        effectiveRuntime = movieRuntimeDf.loc[movieIndex]['effective runtime']\n",
    "        vocEndIndex = list(vocFrame[:]['Time'].values).index(endOfMovie)\n",
    "        vocStartIndex = vocEndIndex - effectiveRuntime\n",
    "        vocWindow = vocFrame[vocStartIndex:vocEndIndex][:]\n",
    "        vocStarWarsAdjusted[index] = vocWindow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign vocs to corresponding movie lists\n",
    "\n",
    "def vocAssignment(matchedMovieList, normalisedVOCList):\n",
    "    hobbitVOCList = list()\n",
    "    walterVOCList = list()\n",
    "    buddyVOCList = list()\n",
    "    macheteVOCList = list()\n",
    "    paranormalActivityVOCList = list()\n",
    "    hungergamesVOCList = list()\n",
    "\n",
    "    for movieIndex in range(0,len(matchedMovieList)):\n",
    "        movie = matchedMovieList[movieIndex]\n",
    "        vocFrame = normalisedVOCList[movieIndex]\n",
    "        if movie == 'Hobbit 2':\n",
    "            hobbitVOCList.append(vocFrame)\n",
    "        elif movie == 'Buddy':\n",
    "            buddyVOCList.append(vocFrame)\n",
    "        elif movie == 'Walter Mitty':\n",
    "            walterVOCList.append(vocFrame)\n",
    "        elif movie == 'Paranormal Activity':\n",
    "            paranormalActivityVOCList.append(vocFrame)\n",
    "        elif movie == 'The Hunger Games-Catching Fire':\n",
    "            hungergamesVOCList.append(vocFrame)\n",
    "        elif movie == 'Machete Kills':\n",
    "            macheteVOCList.append(vocFrame)\n",
    "\n",
    "    #add to a dictionary \n",
    "    movieVOC = dict()\n",
    "    movieVOC['Hobbit 2'] = hobbitVOCList\n",
    "    movieVOC['Buddy'] = buddyVOCList\n",
    "    movieVOC['Walter Mitty'] = walterVOCList\n",
    "    movieVOC['Paranormal Activity'] = paranormalActivityVOCList\n",
    "    movieVOC['The Hunger Games-Catching Fire'] = hungergamesVOCList\n",
    "    movieVOC['Machete Kills'] = macheteVOCList\n",
    "    \n",
    "    return movieVOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save adjusted voc frames, prelim aligned voc frames and delta aligned voc frame\n",
    "\n",
    "deltaAlignedVOC = dict()\n",
    "adjustedVOC = dict()\n",
    "#assign voc frames to each movie\n",
    "adjustedVOC = vocAssignment(matchedMovieList, adjustedVOCList) #manually adjusted\n",
    "deltaAlignedVOC = vocAssignment(matchedMovieList, vocList)     #delta aligned\n",
    "\n",
    "#concatenate 2013 and 2015 lists\n",
    "\n",
    "\n",
    "#add 2015 movies to the adjusted and delta aligned data sets\n",
    "adjustedVOC['I\\'m Off Then'] = vocImOffThenAdjusted\n",
    "adjustedVOC['Help, I\\'ve Shrunk My Teacher'] = vocHelpIShrunkAdjusted\n",
    "adjustedVOC['Star Wars-The Force Awakens'] = vocStarWarsAdjusted\n",
    "\n",
    "deltaAlignedVOC['I\\'m Off Then'] = vocImOffThen\n",
    "deltaAlignedVOC['Help, I\\'ve Shrunk My Teacher'] = vocHelpIShrunk\n",
    "deltaAlignedVOC['Star Wars-The Force Awakens'] = vocStarWars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise voc frames and then save them \n",
    "#normalise the dataframes\n",
    "normalisedVOCList = list()\n",
    "normalisedVOC = dict()\n",
    "\n",
    "for movie in movieList:\n",
    "    screenings = adjustedVOC[movie]\n",
    "    normalisedVOCList = list()\n",
    "    for screeningNumber in range(0, len(screenings)):\n",
    "        screening = screenings[screeningNumber]\n",
    "        normalisedVOCFrame = screening[:]['CO2'].values/max(screening[:]['CO2'].values)\n",
    "        normalisedScreening = screening[:][:]\n",
    "        normalisedScreening[:]['CO2'] = normalisedVOCFrame\n",
    "        normalisedVOCList.append(normalisedScreening)\n",
    "    normalisedVOC[movie] = normalisedVOCList\n",
    "    \n",
    "#save manually adjusted and delta aligned datasets\n",
    "pickle.dump(normalisedVOC, open( \"adjustedVOCs.p\", \"wb\" ) ) #delta aligned and manually adjusted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation - DTW & Distance Checks\n",
    "\n",
    "Dynamic time warp and distance check the adjusted VOC frames\n",
    "\n",
    "Only keep the portions of the voc graphs with close matchings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistanceAugmentation(modifiedBaseScreening, plot2):\n",
    "    #plot1 is the base plot\n",
    "    #plot 2 is the compared plot\n",
    "    modifiedScreening = modifiedBaseScreening[:][:]\n",
    "    modifiedPlot2 = list()\n",
    "    distanceThreshold = 0.01\n",
    "    plot1 = modifiedBaseScreening['CO2'].values\n",
    "    timing = modifiedBaseScreening['Time'].values\n",
    "    timingList = list()\n",
    "    for pointIndex in range(0, len(plot2)):\n",
    "        distance = abs(plot1[pointIndex] - plot2[pointIndex])\n",
    "        if distance <  distanceThreshold:\n",
    "            modifiedPlot2.append(plot2[pointIndex])\n",
    "            timingList.append(timing[pointIndex])\n",
    "        else:\n",
    "            modifiedPlot2.append(nan)\n",
    "            timingList.append(timing[pointIndex])\n",
    "    modifiedScreening[:]['CO2'] = modifiedPlot2\n",
    "    return modifiedScreening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform dynamic time warping and use distance checks \n",
    "def MovieDTW(vocDictionary ,baselineVOC, movieList):\n",
    "    \n",
    "    dtwScreenings = dict()\n",
    "    distanceScreenings = dict()\n",
    "    for movie in movieList:\n",
    "        movieDTWList = list()\n",
    "        movieDistanceList = list()\n",
    "        vocScreenings = vocDictionary[movie]\n",
    "        baseMovie = (baselineVOC[movie]['CO2'].values).reshape(-1,1)\n",
    "        for screening in vocScreenings:\n",
    "            comparedMovie = (screening['CO2'].values).reshape(-1,1)\n",
    "            euclidean_norm = lambda baseMovie, comparedMovie: np.abs(baseMovie - comparedMovie)\n",
    "            dist, cost, acc, path = dtw(baseMovie, comparedMovie, dist=euclidean_norm)\n",
    "            path1 = path[0]\n",
    "            path2 = path[1]\n",
    "\n",
    "            plot1 = baseMovie[path1]\n",
    "            plot2 = comparedMovie[path2]\n",
    "            print(len(baselineVOC[movie]['CO2'].values))\n",
    "            print(len(plot1))\n",
    "            print(len(plot2))\n",
    "            print()\n",
    "#             modifiedBaseScreening = (baselineVOC[movie])[:][:]\n",
    "#             modifiedBaseScreening[:]['CO2'] = plot1\n",
    "            \n",
    "            \n",
    "            movieDTWList.append(plot2)\n",
    "#             modifiedPlot2 = DistanceAugmentation(modifiedBaseScreening, plot2)\n",
    "#             movieDistanceList.append(modifiedPlot2)\n",
    "       \n",
    "        dtwScreenings[movie] = movieDTWList\n",
    "        distanceScreenings[movie] = movieDistanceList\n",
    "        \n",
    "    return dtwScreenings, distanceScreenings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise the dataframes\n",
    "normalisedVOCList = list()\n",
    "normalisedVOC = dict()\n",
    "\n",
    "for movie in movieList:\n",
    "    screenings = adjustedVOC[movie]\n",
    "    normalisedVOCList = list()\n",
    "    for screeningNumber in range(0, len(screenings)):\n",
    "        screening = screenings[screeningNumber]\n",
    "        normalisedVOCFrame = screening[:]['CO2'].values/max(screening[:]['CO2'].values)\n",
    "        normalisedScreening = screening[:][:]\n",
    "        normalisedScreening[:]['CO2'] = normalisedVOCFrame\n",
    "        normalisedVOCList.append(normalisedScreening)\n",
    "    normalisedVOC[movie] = normalisedVOCList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline VOC plots\n",
    "\n",
    "#method: look for baseline VOC curves \n",
    "\n",
    "#Hobbit 18-12-2013 14:00\n",
    "#Machete 23-12-2013 19:35\n",
    "#Buddy 25-12-2013 14:50\n",
    "#Hunger Games 27-12-2013 13:15\n",
    "#Walter 02-01-2014 20:15\n",
    "#Paranormal Activity 09-01-2014 20:35\n",
    "#Star Wars: The Force Awakens 26-12-2015 17:30\n",
    "#I'm Off Then 26-12-2015 17:30\n",
    "#Help, I've Shrunk The Teacher 30-12-2015 11:30\n",
    "\n",
    "\n",
    "#2013 baseline\n",
    "baselineTimeList = list()\n",
    "baselineTimeList.append('10-01-2014 16:30')\n",
    "baselineTimeList.append('23-12-2013 19:35')\n",
    "baselineTimeList.append('25-12-2013 14:50')\n",
    "baselineTimeList.append('27-12-2013 13:15')\n",
    "baselineTimeList.append('02-01-2014 20:15')\n",
    "baselineTimeList.append('09-01-2014 20:35')\n",
    "baselineVOC = dict()\n",
    "for baselineTime in baselineTimeList:\n",
    "    timeIndex = timeList.index(baselineTime)\n",
    "    matchedMovie = matchedMovieList[timeIndex]\n",
    "    vocFrame = adjustedVOCList[timeIndex]\n",
    "    baselineVOC[matchedMovie]= vocFrame\n",
    "\n",
    "#2015 baseline \n",
    "#Star Wars Baseline \n",
    "starWarsBaseline = '26-12-2015 17:30'\n",
    "starWarsIndex = timeListStarWars.index(starWarsBaseline)\n",
    "vocFrame = (normalisedVOC['Star Wars: The Force Awakens'])[starWarsIndex]\n",
    "baselineVOC['Star Wars: The Force Awakens']= vocFrame\n",
    "\n",
    "imOffThenBaseline = '26-12-2015 17:30'\n",
    "imOffThenIndex = timeListImOffThen.index(imOffThenBaseline)\n",
    "vocFrame = (normalisedVOC['I\\'m Off Then'])[imOffThenIndex]\n",
    "baselineVOC['I\\'m Off Then']= vocFrame\n",
    "\n",
    "helpIShrunkBaseline = '30-12-2015 11:30'\n",
    "helpIShrunkIndex = timeListHelpIShrunk.index(helpIShrunkBaseline)\n",
    "vocFrame = (normalisedVOC['Help, I\\'ve Shrunk My Teacher'])[helpIShrunkIndex]\n",
    "baselineVOC['Help, I\\'ve Shrunk My Teacher']= vocFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie data warping\n",
    "movieDTWVOC = dict()\n",
    "movieDistanceVOC = dict()\n",
    "\n",
    "movieDTWVOC, movieDistanceVOC =  MovieDTW(normalisedVOC ,baselineVOC, movieList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                 Time       CO2\n",
       " 380  18-12-2013 14:56  0.969600\n",
       " 381  18-12-2013 14:57  0.969372\n",
       " 382  18-12-2013 14:57  0.969741\n",
       " 383  18-12-2013 14:58  0.970188\n",
       " 384  18-12-2013 14:58  0.970400\n",
       " 385  18-12-2013 14:59  0.970362\n",
       " 386  18-12-2013 14:59  0.968206\n",
       " 387  18-12-2013 15:00  0.967440\n",
       " 388  18-12-2013 15:00  0.968057\n",
       " 389  18-12-2013 15:01  0.968740\n",
       " 390  18-12-2013 15:01  0.968782\n",
       " 391  18-12-2013 15:02  0.969262\n",
       " 392  18-12-2013 15:02  0.972327\n",
       " 393  18-12-2013 15:03  0.974505\n",
       " 394  18-12-2013 15:03  0.977622\n",
       " 395  18-12-2013 15:04  0.979453\n",
       " 396  18-12-2013 15:04  0.979016\n",
       " 397  18-12-2013 15:05  0.979474\n",
       " 398  18-12-2013 15:05  0.980695\n",
       " 399  18-12-2013 15:06  0.981627\n",
       " 400  18-12-2013 15:06  0.982495\n",
       " 401  18-12-2013 15:07  0.983028\n",
       " 402  18-12-2013 15:07  0.983280\n",
       " 403  18-12-2013 15:08  0.983901\n",
       " 404  18-12-2013 15:08  0.984575\n",
       " 405  18-12-2013 15:09  0.985457\n",
       " 406  18-12-2013 15:09  0.985907\n",
       " 407  18-12-2013 15:10  0.984876\n",
       " 408  18-12-2013 15:10  0.983210\n",
       " 409  18-12-2013 15:11  0.981984\n",
       " ..                ...       ...\n",
       " 641  18-12-2013 17:07  0.995634\n",
       " 642  18-12-2013 17:08  0.997424\n",
       " 643  18-12-2013 17:08  0.997034\n",
       " 644  18-12-2013 17:09  0.995813\n",
       " 645  18-12-2013 17:09  0.995775\n",
       " 646  18-12-2013 17:10  0.996255\n",
       " 647  18-12-2013 17:10  0.997822\n",
       " 648  18-12-2013 17:11  0.999178\n",
       " 649  18-12-2013 17:11  0.999173\n",
       " 650  18-12-2013 17:12  0.999699\n",
       " 651  18-12-2013 17:12  1.000000\n",
       " 652  18-12-2013 17:13  0.999528\n",
       " 653  18-12-2013 17:13  0.998180\n",
       " 654  18-12-2013 17:14  0.999951\n",
       " 655  18-12-2013 17:14  0.999982\n",
       " 656  18-12-2013 17:15  0.999461\n",
       " 657  18-12-2013 17:15  0.998706\n",
       " 658  18-12-2013 17:16  0.999042\n",
       " 659  18-12-2013 17:16  0.998330\n",
       " 660  18-12-2013 17:17  0.997526\n",
       " 661  18-12-2013 17:17  0.996482\n",
       " 662  18-12-2013 17:18  0.995576\n",
       " 663  18-12-2013 17:18  0.995939\n",
       " 664  18-12-2013 17:19  0.996321\n",
       " 665  18-12-2013 17:19  0.997607\n",
       " 666  18-12-2013 17:20  0.997857\n",
       " 667  18-12-2013 17:20  0.997502\n",
       " 668  18-12-2013 17:21  0.997100\n",
       " 669  18-12-2013 17:21  0.997305\n",
       " 670  18-12-2013 17:22  0.998462\n",
       " \n",
       " [291 rows x 2 columns],                   Time       CO2\n",
       " 976   18-12-2013 19:56  0.927662\n",
       " 977   18-12-2013 19:56  0.926713\n",
       " 978   18-12-2013 19:57  0.925998\n",
       " 979   18-12-2013 19:57  0.926766\n",
       " 980   18-12-2013 19:58  0.930022\n",
       " 981   18-12-2013 19:58  0.932799\n",
       " 982   18-12-2013 19:59  0.932184\n",
       " 983   18-12-2013 19:59  0.932295\n",
       " 984   18-12-2013 20:00  0.933472\n",
       " 985   18-12-2013 20:00  0.935159\n",
       " 986   18-12-2013 20:01  0.936524\n",
       " 987   18-12-2013 20:01  0.937789\n",
       " 988   18-12-2013 20:02  0.940126\n",
       " 989   18-12-2013 20:02  0.943032\n",
       " 990   18-12-2013 20:03  0.947056\n",
       " 991   18-12-2013 20:03  0.951097\n",
       " 992   18-12-2013 20:04  0.955209\n",
       " 993   18-12-2013 20:04  0.957546\n",
       " 994   18-12-2013 20:05  0.959321\n",
       " 995   18-12-2013 20:05  0.958337\n",
       " 996   18-12-2013 20:06  0.957634\n",
       " 997   18-12-2013 20:06  0.956785\n",
       " 998   18-12-2013 20:07  0.956205\n",
       " 999   18-12-2013 20:07  0.957927\n",
       " 1000  18-12-2013 20:08  0.959807\n",
       " 1001  18-12-2013 20:08  0.959491\n",
       " 1002  18-12-2013 20:09  0.956427\n",
       " 1003  18-12-2013 20:09  0.954090\n",
       " 1004  18-12-2013 20:10  0.953756\n",
       " 1005  18-12-2013 20:10  0.954963\n",
       " ...                ...       ...\n",
       " 1237  18-12-2013 22:07  0.968488\n",
       " 1238  18-12-2013 22:07  0.971773\n",
       " 1239  18-12-2013 22:08  0.974895\n",
       " 1240  18-12-2013 22:08  0.976623\n",
       " 1241  18-12-2013 22:09  0.975979\n",
       " 1242  18-12-2013 22:09  0.975112\n",
       " 1243  18-12-2013 22:10  0.974245\n",
       " 1244  18-12-2013 22:10  0.973320\n",
       " 1245  18-12-2013 22:11  0.972881\n",
       " 1246  18-12-2013 22:11  0.973121\n",
       " 1247  18-12-2013 22:12  0.972863\n",
       " 1248  18-12-2013 22:12  0.973396\n",
       " 1249  18-12-2013 22:13  0.972986\n",
       " 1250  18-12-2013 22:13  0.972025\n",
       " 1251  18-12-2013 22:14  0.972564\n",
       " 1252  18-12-2013 22:14  0.973736\n",
       " 1253  18-12-2013 22:15  0.973138\n",
       " 1254  18-12-2013 22:15  0.972207\n",
       " 1255  18-12-2013 22:16  0.971703\n",
       " 1256  18-12-2013 22:16  0.968903\n",
       " 1257  18-12-2013 22:17  0.966935\n",
       " 1258  18-12-2013 22:17  0.965225\n",
       " 1259  18-12-2013 22:18  0.965846\n",
       " 1260  18-12-2013 22:18  0.965102\n",
       " 1261  18-12-2013 22:19  0.964399\n",
       " 1262  18-12-2013 22:19  0.963474\n",
       " 1263  18-12-2013 22:20  0.964985\n",
       " 1264  18-12-2013 22:20  0.964370\n",
       " 1265  18-12-2013 22:21  0.965178\n",
       " 1266  18-12-2013 22:21  0.969700\n",
       " \n",
       " [291 rows x 2 columns],                    Time       CO2\n",
       " 12583  22-12-2013 21:11  0.980871\n",
       " 12584  22-12-2013 21:12  0.980024\n",
       " 12585  22-12-2013 21:12  0.979747\n",
       " 12586  22-12-2013 21:13  0.979147\n",
       " 12587  22-12-2013 21:13  0.978285\n",
       " 12588  22-12-2013 21:14  0.978780\n",
       " 12589  22-12-2013 21:14  0.979035\n",
       " 12590  22-12-2013 21:15  0.980227\n",
       " 12591  22-12-2013 21:15  0.980586\n",
       " 12592  22-12-2013 21:16  0.979964\n",
       " 12593  22-12-2013 21:16  0.979395\n",
       " 12594  22-12-2013 21:17  0.981448\n",
       " 12595  22-12-2013 21:17  0.982895\n",
       " 12596  22-12-2013 21:18  0.985668\n",
       " 12597  22-12-2013 21:18  0.988742\n",
       " 12598  22-12-2013 21:19  0.990473\n",
       " 12599  22-12-2013 21:19  0.991432\n",
       " 12600  22-12-2013 21:20  0.990556\n",
       " 12601  22-12-2013 21:20  0.988876\n",
       " 12602  22-12-2013 21:21  0.986680\n",
       " 12603  22-12-2013 21:21  0.985511\n",
       " 12604  22-12-2013 21:22  0.983180\n",
       " 12605  22-12-2013 21:22  0.983562\n",
       " 12606  22-12-2013 21:23  0.983337\n",
       " 12607  22-12-2013 21:23  0.984274\n",
       " 12608  22-12-2013 21:24  0.983120\n",
       " 12609  22-12-2013 21:24  0.981741\n",
       " 12610  22-12-2013 21:25  0.979559\n",
       " 12611  22-12-2013 21:25  0.979574\n",
       " 12612  22-12-2013 21:26  0.978825\n",
       " ...                 ...       ...\n",
       " 12844  22-12-2013 23:22  0.923020\n",
       " 12845  22-12-2013 23:23  0.924339\n",
       " 12846  22-12-2013 23:23  0.923327\n",
       " 12847  22-12-2013 23:24  0.922338\n",
       " 12848  22-12-2013 23:24  0.921551\n",
       " 12849  22-12-2013 23:25  0.920914\n",
       " 12850  22-12-2013 23:25  0.920996\n",
       " 12851  22-12-2013 23:26  0.920052\n",
       " 12852  22-12-2013 23:26  0.919332\n",
       " 12853  22-12-2013 23:27  0.917428\n",
       " 12854  22-12-2013 23:27  0.917496\n",
       " 12855  22-12-2013 23:28  0.917983\n",
       " 12856  22-12-2013 23:28  0.918837\n",
       " 12857  22-12-2013 23:29  0.919662\n",
       " 12858  22-12-2013 23:29  0.917481\n",
       " 12859  22-12-2013 23:30  0.916266\n",
       " 12860  22-12-2013 23:30  0.915187\n",
       " 12861  22-12-2013 23:31  0.912466\n",
       " 12862  22-12-2013 23:31  0.910787\n",
       " 12863  22-12-2013 23:32  0.909130\n",
       " 12864  22-12-2013 23:32  0.909835\n",
       " 12865  22-12-2013 23:33  0.908613\n",
       " 12866  22-12-2013 23:33  0.909175\n",
       " 12867  22-12-2013 23:34  0.910240\n",
       " 12868  22-12-2013 23:34  0.910660\n",
       " 12869  22-12-2013 23:35  0.909100\n",
       " 12870  22-12-2013 23:35  0.913103\n",
       " 12871  22-12-2013 23:36  0.920584\n",
       " 12872  22-12-2013 23:36  0.924789\n",
       " 12873  22-12-2013 23:37  0.928004\n",
       " \n",
       " [291 rows x 2 columns],                    Time       CO2\n",
       " 66260  10-01-2014 17:24  0.926541\n",
       " 66261  10-01-2014 17:24  0.929196\n",
       " 66262  10-01-2014 17:25  0.929750\n",
       " 66263  10-01-2014 17:25  0.929192\n",
       " 66264  10-01-2014 17:26  0.930424\n",
       " 66265  10-01-2014 17:26  0.931067\n",
       " 66266  10-01-2014 17:27  0.933308\n",
       " 66267  10-01-2014 17:27  0.937866\n",
       " 66268  10-01-2014 17:28  0.938800\n",
       " 66269  10-01-2014 17:28  0.939829\n",
       " 66270  10-01-2014 17:29  0.940000\n",
       " 66271  10-01-2014 17:29  0.938334\n",
       " 66272  10-01-2014 17:30  0.940069\n",
       " 66273  10-01-2014 17:30  0.938685\n",
       " 66274  10-01-2014 17:31  0.941588\n",
       " 66275  10-01-2014 17:31  0.945110\n",
       " 66276  10-01-2014 17:32  0.947621\n",
       " 66277  10-01-2014 17:32  0.947556\n",
       " 66278  10-01-2014 17:33  0.948749\n",
       " 66279  10-01-2014 17:33  0.945294\n",
       " 66280  10-01-2014 17:34  0.947332\n",
       " 66281  10-01-2014 17:34  0.949813\n",
       " 66282  10-01-2014 17:35  0.948873\n",
       " 66283  10-01-2014 17:35  0.951348\n",
       " 66284  10-01-2014 17:36  0.953125\n",
       " 66285  10-01-2014 17:36  0.955903\n",
       " 66286  10-01-2014 17:37  0.955092\n",
       " 66287  10-01-2014 17:37  0.957110\n",
       " 66288  10-01-2014 17:38  0.954524\n",
       " 66289  10-01-2014 17:38  0.952035\n",
       " ...                 ...       ...\n",
       " 66521  10-01-2014 19:35  0.977734\n",
       " 66522  10-01-2014 19:35  0.977348\n",
       " 66523  10-01-2014 19:36  0.974471\n",
       " 66524  10-01-2014 19:36  0.975585\n",
       " 66525  10-01-2014 19:37  0.977397\n",
       " 66526  10-01-2014 19:37  0.976263\n",
       " 66527  10-01-2014 19:38  0.976894\n",
       " 66528  10-01-2014 19:38  0.975424\n",
       " 66529  10-01-2014 19:39  0.975955\n",
       " 66530  10-01-2014 19:39  0.980960\n",
       " 66531  10-01-2014 19:40  0.980531\n",
       " 66532  10-01-2014 19:40  0.979746\n",
       " 66533  10-01-2014 19:41  0.979724\n",
       " 66534  10-01-2014 19:41  0.978305\n",
       " 66535  10-01-2014 19:42  0.976885\n",
       " 66536  10-01-2014 19:42  0.977495\n",
       " 66537  10-01-2014 19:43  0.979453\n",
       " 66538  10-01-2014 19:43  0.979257\n",
       " 66539  10-01-2014 19:44  0.977699\n",
       " 66540  10-01-2014 19:44  0.980646\n",
       " 66541  10-01-2014 19:45  0.976244\n",
       " 66542  10-01-2014 19:45  0.976731\n",
       " 66543  10-01-2014 19:46  0.978972\n",
       " 66544  10-01-2014 19:46  0.981301\n",
       " 66545  10-01-2014 19:47  0.979053\n",
       " 66546  10-01-2014 19:47  0.978567\n",
       " 66547  10-01-2014 19:48  0.976789\n",
       " 66548  10-01-2014 19:48  0.978763\n",
       " 66549  10-01-2014 19:49  0.974857\n",
       " 66550  10-01-2014 19:49  0.975868\n",
       " \n",
       " [291 rows x 2 columns],                    Time       CO2\n",
       " 69136  11-01-2014 17:25  0.882770\n",
       " 69137  11-01-2014 17:25  0.884139\n",
       " 69138  11-01-2014 17:26  0.886651\n",
       " 69139  11-01-2014 17:26  0.889958\n",
       " 69140  11-01-2014 17:27  0.892152\n",
       " 69141  11-01-2014 17:27  0.893192\n",
       " 69142  11-01-2014 17:28  0.890218\n",
       " 69143  11-01-2014 17:28  0.893444\n",
       " 69144  11-01-2014 17:29  0.900370\n",
       " 69145  11-01-2014 17:29  0.900975\n",
       " 69146  11-01-2014 17:30  0.903579\n",
       " 69147  11-01-2014 17:30  0.907254\n",
       " 69148  11-01-2014 17:31  0.908852\n",
       " 69149  11-01-2014 17:31  0.913369\n",
       " 69150  11-01-2014 17:32  0.914691\n",
       " 69151  11-01-2014 17:32  0.913819\n",
       " 69152  11-01-2014 17:33  0.914261\n",
       " 69153  11-01-2014 17:33  0.916102\n",
       " 69154  11-01-2014 17:34  0.924610\n",
       " 69155  11-01-2014 17:34  0.922767\n",
       " 69156  11-01-2014 17:35  0.922180\n",
       " 69157  11-01-2014 17:35  0.926219\n",
       " 69158  11-01-2014 17:36  0.930740\n",
       " 69159  11-01-2014 17:36  0.930404\n",
       " 69160  11-01-2014 17:37  0.929843\n",
       " 69161  11-01-2014 17:37  0.926712\n",
       " 69162  11-01-2014 17:38  0.929986\n",
       " 69163  11-01-2014 17:38  0.929640\n",
       " 69164  11-01-2014 17:39  0.930503\n",
       " 69165  11-01-2014 17:39  0.930459\n",
       " ...                 ...       ...\n",
       " 69397  11-01-2014 19:36  0.998423\n",
       " 69398  11-01-2014 19:36  0.994345\n",
       " 69399  11-01-2014 19:37  0.993700\n",
       " 69400  11-01-2014 19:37  0.989841\n",
       " 69401  11-01-2014 19:38  0.989216\n",
       " 69402  11-01-2014 19:38  0.986840\n",
       " 69403  11-01-2014 19:39  0.989926\n",
       " 69404  11-01-2014 19:39  0.995593\n",
       " 69405  11-01-2014 19:40  0.991434\n",
       " 69406  11-01-2014 19:40  0.987775\n",
       " 69407  11-01-2014 19:41  0.986574\n",
       " 69408  11-01-2014 19:41  0.987726\n",
       " 69409  11-01-2014 19:42  0.988695\n",
       " 69410  11-01-2014 19:42  0.988356\n",
       " 69411  11-01-2014 19:43  0.986217\n",
       " 69412  11-01-2014 19:43  0.987494\n",
       " 69413  11-01-2014 19:44  0.991571\n",
       " 69414  11-01-2014 19:44  0.985730\n",
       " 69415  11-01-2014 19:45  0.985959\n",
       " 69416  11-01-2014 19:45  0.985318\n",
       " 69417  11-01-2014 19:46  0.981552\n",
       " 69418  11-01-2014 19:46  0.975948\n",
       " 69419  11-01-2014 19:47  0.971206\n",
       " 69420  11-01-2014 19:47  0.973922\n",
       " 69421  11-01-2014 19:48  0.974356\n",
       " 69422  11-01-2014 19:48  0.980867\n",
       " 69423  11-01-2014 19:49  0.988029\n",
       " 69424  11-01-2014 19:49  0.991076\n",
       " 69425  11-01-2014 19:50  0.993292\n",
       " 69426  11-01-2014 19:50  0.990737\n",
       " \n",
       " [291 rows x 2 columns]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(0,len(movieDTWVOC['Hobbit 2'])):\n",
    "#     plt.figure()\n",
    "#     plt.plot((movieDTWVOC['Hobbit 2'])[i])\n",
    "#     plt.plot((movieDistanceVOC['Hobbit 2'])[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if movie length is not the same as the baseline then DTW has failed in places must remove those places "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save required data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Windowing</h3>\n",
    "\n",
    "<b>Pseudo-code</b>\n",
    "\n",
    "PREPROCESS\n",
    "\n",
    "- take use the start and end time to get the global time index\n",
    "- then add 2.5 mins to the start and end of the movie\n",
    "\n",
    "WINDOWING\n",
    "\n",
    "- use the actual start of the movie as the centre point of the window\n",
    "- add 2.5 mins (5 intervals) previous to the centre point and 2.5 mins (5 intervals) after the centre point\n",
    "- save that as coloumns in a dataframe \n",
    "\n",
    "Final dataframe should contain the window in line with the various film features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowing(screening):\n",
    "    #take "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "- Randomly remove a screening from each movie to create the training and test dataset\n",
    "- Randomly remove rows from the entire (concatenated) dataset to create a train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83427036],\n",
       "       [0.83864006],\n",
       "       [0.83623673],\n",
       "       [0.83621386],\n",
       "       [0.83942254],\n",
       "       [0.84142828],\n",
       "       [0.84373126],\n",
       "       [0.84689421],\n",
       "       [0.84895203],\n",
       "       [0.85125883],\n",
       "       [0.85308673],\n",
       "       [0.85505437],\n",
       "       [0.85828337],\n",
       "       [0.85957777],\n",
       "       [0.85982547],\n",
       "       [0.86096235],\n",
       "       [0.86259972],\n",
       "       [0.86474773],\n",
       "       [0.86776587],\n",
       "       [0.86850516],\n",
       "       [0.86946547],\n",
       "       [0.87019714],\n",
       "       [0.87363701],\n",
       "       [0.878793  ],\n",
       "       [0.87960724],\n",
       "       [0.88027539],\n",
       "       [0.88437579],\n",
       "       [0.88656445],\n",
       "       [0.88968802],\n",
       "       [0.89384686],\n",
       "       [0.89407804],\n",
       "       [0.89424699],\n",
       "       [0.89535212],\n",
       "       [0.89845536],\n",
       "       [0.90066816],\n",
       "       [0.90028581],\n",
       "       [0.90137061],\n",
       "       [0.90398227],\n",
       "       [0.90634749],\n",
       "       [0.90958666],\n",
       "       [0.91176007],\n",
       "       [0.91290839],\n",
       "       [0.91148062],\n",
       "       [0.91134343],\n",
       "       [0.91100808],\n",
       "       [0.91310655],\n",
       "       [0.91373533],\n",
       "       [0.91452543],\n",
       "       [0.9150691 ],\n",
       "       [0.91795767],\n",
       "       [0.91940704],\n",
       "       [0.92157919],\n",
       "       [0.92427849],\n",
       "       [0.92598191],\n",
       "       [0.92730679],\n",
       "       [0.92968599],\n",
       "       [0.93149865],\n",
       "       [0.93203724],\n",
       "       [0.93273081],\n",
       "       [0.93674483],\n",
       "       [0.94144733],\n",
       "       [0.94036634],\n",
       "       [0.94040191],\n",
       "       [0.93995986],\n",
       "       [0.9399154 ],\n",
       "       [0.9395013 ],\n",
       "       [0.93938189],\n",
       "       [0.93770515],\n",
       "       [0.93660129],\n",
       "       [0.93644632],\n",
       "       [0.93725547],\n",
       "       [0.9379719 ],\n",
       "       [0.93986332],\n",
       "       [0.94116788],\n",
       "       [0.94337178],\n",
       "       [0.9435204 ],\n",
       "       [0.94426096],\n",
       "       [0.94439307],\n",
       "       [0.94177506],\n",
       "       [0.94092526],\n",
       "       [0.94090112],\n",
       "       [0.94185001],\n",
       "       [0.94173568],\n",
       "       [0.94273157],\n",
       "       [0.94619049],\n",
       "       [0.94918576],\n",
       "       [0.94876912],\n",
       "       [0.94862431],\n",
       "       [0.94782277],\n",
       "       [0.94943346],\n",
       "       [0.95113434],\n",
       "       [0.95119786],\n",
       "       [0.95099334],\n",
       "       [0.95128677],\n",
       "       [0.95284919],\n",
       "       [0.95072405],\n",
       "       [0.9487399 ],\n",
       "       [0.94912098],\n",
       "       [0.95136553],\n",
       "       [0.95266755],\n",
       "       [0.95426299],\n",
       "       [0.95727859],\n",
       "       [0.95845867],\n",
       "       [0.95888674],\n",
       "       [0.95990803],\n",
       "       [0.95807251],\n",
       "       [0.95662314],\n",
       "       [0.95609217],\n",
       "       [0.95827702],\n",
       "       [0.960956  ],\n",
       "       [0.96235583],\n",
       "       [0.96145394],\n",
       "       [0.96079468],\n",
       "       [0.96021163],\n",
       "       [0.96055714],\n",
       "       [0.9612037 ],\n",
       "       [0.96324628],\n",
       "       [0.96718282],\n",
       "       [0.96985671],\n",
       "       [0.96961028],\n",
       "       [0.97016158],\n",
       "       [0.96860805],\n",
       "       [0.96717646],\n",
       "       [0.96691987],\n",
       "       [0.96624282],\n",
       "       [0.96746862],\n",
       "       [0.96847213],\n",
       "       [0.97114603],\n",
       "       [0.97255602],\n",
       "       [0.97247853],\n",
       "       [0.97072684],\n",
       "       [0.96961918],\n",
       "       [0.97086784],\n",
       "       [0.97249251],\n",
       "       [0.97357477],\n",
       "       [0.97643539],\n",
       "       [0.98026015],\n",
       "       [0.98324526],\n",
       "       [0.98324526],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98601824],\n",
       "       [0.98756415],\n",
       "       [0.9883606 ],\n",
       "       [0.98859179],\n",
       "       [0.98843301],\n",
       "       [0.98750572],\n",
       "       [0.98780042],\n",
       "       [0.9894543 ],\n",
       "       [0.99097353],\n",
       "       [0.99097353],\n",
       "       [0.99097353],\n",
       "       [0.99097353],\n",
       "       [0.99097353],\n",
       "       [0.99097353],\n",
       "       [0.99097353],\n",
       "       [0.99035618],\n",
       "       [0.98834155],\n",
       "       [0.98592932],\n",
       "       [0.98489025],\n",
       "       [0.98269651],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98083304],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.98084193],\n",
       "       [0.97871551],\n",
       "       [0.97871297],\n",
       "       [0.97886667],\n",
       "       [0.9780283 ],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97577359],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.97384914],\n",
       "       [0.9746583 ],\n",
       "       [0.97400666],\n",
       "       [0.97391901],\n",
       "       [0.97732458],\n",
       "       [0.97732458],\n",
       "       [0.98325161],\n",
       "       [0.98900335],\n",
       "       [0.98900335],\n",
       "       [0.99358899],\n",
       "       [0.99358899],\n",
       "       [0.99626035],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99859382],\n",
       "       [0.99972943],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train/test split - by screening \n",
    "#randomly select and remove one screening\n",
    "\n",
    "hungergamesTestIndex = random.randint(0, len(hungergamesDTWVOCList)-1)\n",
    "hungergamesTest = hungergamesDTWVOCList[hungergamesTestIndex]\n",
    "hungergamesTrain = hungergamesDTWVOCList[:]\n",
    "hungergamesTrain.pop(hungergamesTestIndex)\n",
    "\n",
    "hobbit2TestIndex = random.randint(0, len(hobbitDTWVOCList)-1)\n",
    "hobbit2Test = hobbitDTWVOCList[hobbit2TestIndex]\n",
    "hobbit2Train = hobbitDTWVOCList[:]\n",
    "hobbit2Train.pop(hobbit2TestIndex)\n",
    "\n",
    "paranormalActivityTestIndex = random.randint(0, len(paranormalDTWVOCList)-1)\n",
    "paranormalActivityTest = paranormalDTWVOCList[paranormalActivityTestIndex]\n",
    "paranormalActivityTrain = paranormalDTWVOCList[:]\n",
    "paranormalActivityTrain.pop(paranormalActivityTestIndex)\n",
    "\n",
    "macheteTestIndex = random.randint(0, len(macheteDTWVOCList)-1)\n",
    "macheteTest = macheteDTWVOCList[macheteTestIndex]\n",
    "macheteTrain = macheteDTWVOCList[:]\n",
    "macheteTrain.pop(macheteTestIndex)\n",
    "\n",
    "walterTestIndex = random.randint(0, len(walterDTWVOCList)-1)\n",
    "walterTest = walterDTWVOCList[walterTestIndex]\n",
    "walterTrain = walterDTWVOCList[:]\n",
    "walterTrain.pop(walterTestIndex)\n",
    "\n",
    "buddyTestIndex = random.randint(0, len(buddyDTWVOCList)-1)\n",
    "buddyTest = buddyDTWVOCList[buddyTestIndex]\n",
    "buddyTrain = buddyDTWVOCList[:]\n",
    "buddyTrain.pop(buddyTestIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
