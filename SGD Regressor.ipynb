{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Implementation Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the new data then train on that new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = 10, 5\n",
    "np.random.seed(0)\n",
    "y = np.random.randn(n_samples)\n",
    "X = np.random.randn(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sof/.local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/sof/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.SGDRegressor()\n",
    "rmseList = list()\n",
    "for instanceIndex in range(0, len(X)):\n",
    "    instance = X[instanceIndex].reshape(1, -1)\n",
    "    label = y[instanceIndex].reshape(-1, 1)\n",
    "    if instanceIndex == 0:\n",
    "        #train the model\n",
    "        clf.fit(instance,label)\n",
    "    else:\n",
    "        #test the model\n",
    "        predicted = clf.predict(instance)\n",
    "        #get rmse\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(label, predicted))\n",
    "        rmseList.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22059874602133628,\n",
       " 0.7705616994897968,\n",
       " 2.138493820098493,\n",
       " 1.834517235547889,\n",
       " 1.211007783645852,\n",
       " 1.1151303563431092,\n",
       " 0.1128506255106105,\n",
       " 0.16181025119858136,\n",
       " 0.3347571060085341]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmseList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import DataPipeline\n",
    "from sklearn import linear_model\n",
    "import pickle\n",
    "from math import trunc\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRandomisedVOCScreenings(vocRandomised, runtimeList, movieList ,matchedMovies):\n",
    "    startIndex = 0\n",
    "    screeningList = list()\n",
    "    for movie in matchedMovies:\n",
    "        try:\n",
    "            runtime = runtimeList[movieList.index(movie)]\n",
    "        except ValueError:\n",
    "            continue\n",
    "        endIndex = startIndex + runtime\n",
    "        screening = vocRandomised[startIndex:endIndex]\n",
    "        screeningList.append(screening)\n",
    "        startIndex = endIndex\n",
    "    return screeningList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateVOCScreenings(vocDf2013,vocDf2015, sliceDf, matchedMovies):\n",
    "    screeningList = list()\n",
    "    prevStartIndex = 0\n",
    "    startIndex = 0\n",
    "    vocDf = vocDf2013\n",
    "    for index in range(0, len(matchedMovies)):\n",
    "        \n",
    "        startIndex = sliceDf.loc[index]['start']\n",
    "        endIndex = sliceDf.loc[index]['end']\n",
    "        if startIndex == 371: #the 2015 df starts at this index\n",
    "            vocDf = vocDf2015\n",
    "        screening = pd.DataFrame(vocDf.iloc[startIndex:endIndex+1,0])\n",
    "        screeningList.append(screening)\n",
    "        \n",
    "        prevStartIndex = startIndex\n",
    "        \n",
    "    return screeningList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation(vocScreenings, voc):\n",
    "    normalisedVOCList = list()\n",
    "    for screening in vocScreenings:\n",
    "        normalisedVOCFrame = copy.deepcopy(screening)\n",
    "        normalisedVOCFrame = normalisedVOCFrame.values/max(screening.values)\n",
    "        normalisedVOCFrame = normalisedVOCFrame.flatten()\n",
    "        normalisedScreening= pd.DataFrame.from_dict({voc:normalisedVOCFrame})\n",
    "        normalisedVOCList.append(normalisedScreening)\n",
    "    return normalisedVOCList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some vocs have NaN measurements during the decided screening times. Ignore these screenings\n",
    "#also remove empty screenings\n",
    "def removeNaNScreenings(screenings, randomisedScreenings, matchedMovies):\n",
    "    screeningList = list()\n",
    "    randomScreeningList = list()\n",
    "    movieList = list()\n",
    "    for screeningIndex in range(0, len(screenings)):\n",
    "        if not(np.isnan(screenings[screeningIndex].values).any()) and len(screenings[screeningIndex].values) != 0:\n",
    "            screeningList.append(screenings[screeningIndex])\n",
    "            randomScreeningList.append(randomisedScreenings[screeningIndex])\n",
    "            movieList.append(matchedMovies[screeningIndex])\n",
    "    return screeningList,randomScreeningList,movieList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column header matching issue between 2013 and 2015 \n",
    "#e.g. in 2015 column is m356.0711 vs in 2013 is it m356.0714\n",
    "#assumption being made is that they are the same column so round to 2dp and match\n",
    "def vocRounding(vocDf):\n",
    "    vocList = list()\n",
    "    for index in range(0, len(vocDf.columns)):\n",
    "        if vocDf.columns[index] == 'Time' or vocDf.columns[index] == 'ocs' or vocDf.columns[index] == 'co' or vocDf.columns[index] == 'CO2':\n",
    "            vocList.append(vocDf.columns[index])    \n",
    "        else:\n",
    "            #string slice to get the molar mass\n",
    "            voc = vocDf.columns[index]\n",
    "            mass = (trunc(float(voc[1:])*1000))/1000 #TRUNCATE TO 3DP\n",
    "            vocList.append(mass)\n",
    "    return vocList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frames were collected at 1/3fps so for a 30 second period there are 10 frames. This function just groups the \n",
    "#dominant frame colour or shade components to within their respective intervals\n",
    "def grouping(visualList):\n",
    "    movieVisuals = list()\n",
    "    for index in range(0, int(len(visualList)/10)):\n",
    "        segment = visualList[index*10:index*10+10]\n",
    "        movieVisuals.append(segment)\n",
    "    return movieVisuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processVisuals(movieVisualData, runtime, isColour):\n",
    "    visualDataIntervals = grouping(movieVisualData)\n",
    "    #the visual data also has the credits accounted for so remove them\n",
    "    visualDataIntervals = visualDataIntervals[:runtime]\n",
    "    #create a dataframe \n",
    "    if isColour: \n",
    "        #create a dominant colour dataframe\n",
    "        framesPerInterval = 10\n",
    "        header = list();\n",
    "        for i in range(1,framesPerInterval+1):\n",
    "            header = header + ['R'+str(i), 'G' + str(i),  'B'+str(i)]\n",
    "    else: #shade object to be parsed\n",
    "        framesPerInterval = 10\n",
    "        header = ['S' + str(x) for x in range(1,framesPerInterval+1)]\n",
    "    \n",
    "    visualDf = pd.DataFrame(columns=header)\n",
    "    #assemble the dataframe\n",
    "    for segment in visualDataIntervals:\n",
    "        index = visualDataIntervals.index(segment)\n",
    "        colourRow = list()\n",
    "        for colour in segment:\n",
    "            if isColour:\n",
    "                colourRow = colourRow + [colour[0], colour[1], colour[2]]\n",
    "            else:\n",
    "                colourRow = colourRow + [colour[0]]\n",
    "        #assign that colour row to the dataframe\n",
    "        visualDf.loc[index] = colourRow\n",
    "            \n",
    "    return visualDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAudio(runtime, audio):\n",
    "    audioFeatures = list(audio.keys())\n",
    "\n",
    "    audioDf = pd.DataFrame(columns=[])        \n",
    "    for key in audioFeatures:\n",
    "        audio[key] = audio[key][:runtime]\n",
    "\n",
    "        #assemble df \n",
    "        #create header\n",
    "        if key != 'tempo':\n",
    "            header = [key + str(x) for x in range(1, len(audio[key][0])+1)]\n",
    "        else:\n",
    "            header = ['tempo']\n",
    "\n",
    "        audioFeatureDf = pd.DataFrame(columns=header)\n",
    "        for index in range(0, len(audio[key])):\n",
    "            feature = audio[key][index]\n",
    "            audioFeatureDf.loc[index] = feature\n",
    "\n",
    "        #concatenate featureDf to audioDf\n",
    "        audioDf = pd.concat([audioDf,audioFeatureDf], axis=1)\n",
    "    \n",
    "    return audioDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSubtitles(subs, effectiveRuntime):\n",
    "    \n",
    "    header = ['sentiment value']\n",
    "    subSentimentDf = pd.DataFrame(columns=header)\n",
    "    for sentimentIndex in range(0, len(subs)):\n",
    "        sentiment = subs[sentimentIndex]\n",
    "        if len(sentiment) != 0:\n",
    "            if sentiment['sentimentValue'] == np.NaN:\n",
    "                print('YES')\n",
    "            else:         \n",
    "                subSentimentDf.loc[sentimentIndex] = [sentiment['sentimentValue']]\n",
    "        else:\n",
    "            subSentimentDf.loc[sentimentIndex] = [-1] #indicates no dialog occurred during the scene\n",
    "        \n",
    "        #enforce no dialog until the credit scene if there is in fact no dialog\n",
    "        if len(subSentimentDf) != effectiveRuntime:\n",
    "            #no dialog at the end thus need to fill the rest with -1\n",
    "            for index in range(0, effectiveRuntime-len(subSentimentDf)+1):\n",
    "                 subSentimentDf.loc[index] = [-1]\n",
    "    \n",
    "    return subSentimentDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processASL(asl, effectiveRuntime):\n",
    "    \n",
    "    header = ['average shot length']\n",
    "    aslDf = pd.DataFrame(columns=header)\n",
    "    for index in range(0, effectiveRuntime): \n",
    "        aslValue = asl[index]\n",
    "        aslDf.loc[index] = aslValue\n",
    "    \n",
    "    return aslDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeMovies(vocDict):\n",
    "\n",
    "    #remove all screenings of im off then and help i shrunk the teacher as at the current time do not have the movies\n",
    "    screenings = list()\n",
    "    matchedMovies = list()\n",
    "    for movieIndex in range(0, len(vocDict['matchedMovies'])):\n",
    "        movie = vocDict['matchedMovies'][movieIndex]\n",
    "        if movie != \"Help, I Shrunk My Teacher\" and movie != \"I'm Off Then\":\n",
    "            #add good screenings to a modified screening list\n",
    "            matchedMovies.append(movie)\n",
    "            screenings.append(vocDict['screenings'][movieIndex])\n",
    "    #replace\n",
    "    vocDict = dict()\n",
    "    vocDict['matchedMovies'] = matchedMovies\n",
    "    vocDict['screenings'] = screenings\n",
    "    \n",
    "    return vocDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user macros\n",
    "featureDf = pd.DataFrame([]) #film feature dataframe\n",
    "labelDf = pd.DataFrame([]) #voc dataframe\n",
    "deltaVOCs = False\n",
    "windowedVOCs = False\n",
    "lengthOfWindow = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the various csvs\n",
    "#2013 Dataset\n",
    "vocPath = 'Numerical Data/2013VOCData.csv'\n",
    "voc2013DfAll = pd.read_csv(vocPath, header = 0, nrows = 74208, low_memory=False)\n",
    "movieScreeningsPath = 'Numerical Data/screening_times.csv'\n",
    "movingScreeningsDf = pd.read_csv(movieScreeningsPath, usecols = ['scheduled','movie','filled %'])\n",
    "movieRuntimesPath = 'Numerical Data/movie_runtimes.csv'\n",
    "movieRuntimeDf = pd.read_csv(movieRuntimesPath, usecols = ['movie', 'runtime (mins)', 'effective runtime'])\n",
    "#2015 Dataset\n",
    "starWarsPath = 'Numerical Data/Star Wars-The Force Awakens.csv'\n",
    "starWarsScreeningDf = pd.read_csv(starWarsPath)\n",
    "imOffThenPath = 'Numerical Data/I\\'m Off Then.csv'\n",
    "imOffThenScreeningDf = pd.read_csv(imOffThenPath)\n",
    "helpIShrunkTheTeacherPath = 'Numerical Data/Help, I Shrunk My Teacher.csv'\n",
    "helpIShrunkTheTeacherScreeningDf = pd.read_csv(helpIShrunkTheTeacherPath)\n",
    "vocPath = 'Numerical Data/2015VOCData.csv'\n",
    "voc2015DfAll = pd.read_csv(vocPath)\n",
    "#remove first column of 2015 voc df as its not used\n",
    "voc2015DfAll.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "#import co2Slice pickle objects\n",
    "slicePath = 'Pickle Objects/CO2SliceDict.p'\n",
    "sliceDict = pickle.load(open(slicePath, \"rb\" )) #contains df of co2 slice indices and matched movie list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall feature and labels df\n",
    "featureDf = pd.DataFrame([]) #film feature dataframe\n",
    "labelDf = pd.DataFrame([]) #voc dataframe\n",
    "\n",
    "#import movie runtimes\n",
    "movieRuntimesPath = 'Numerical Data/movie_runtimes.csv'\n",
    "movieRuntimeDf = pd.read_csv(movieRuntimesPath, usecols = ['movie', 'runtime (mins)', 'effective runtime'])\n",
    "movieList = list(movieRuntimeDf['movie'])\n",
    "\n",
    "movieFeatureDict = dict() #dict contains the movie film features with the keys being the movies\n",
    "#import pickle objects for movies and then assemble the dataframes  \n",
    "for movie in movieList:\n",
    "    try:\n",
    "        #load pickle feauture objects\n",
    "        featurePath = 'Pickle Objects/Audio Feature Pickle Objects/' + movie + '.p'\n",
    "        audio = pickle.load(open(featurePath, \"rb\" )) \n",
    "        featurePath = 'Pickle Objects/Colour Pickle Objects/' + movie + '.p'\n",
    "        colour = pickle.load(open(featurePath, \"rb\" )) \n",
    "        featurePath = 'Pickle Objects/Shade Pickle Objects/' + movie + '.p'\n",
    "        shade = pickle.load(open(featurePath, \"rb\" )) \n",
    "        featurePath = 'Pickle Objects/Subtitle Sentiment Pickle Objects/' + movie + '.p'\n",
    "        sentiment = pickle.load(open(featurePath, \"rb\" )) \n",
    "        featurePath = 'Pickle Objects/ASL Pickle Objects/' + movie + '.p'\n",
    "        asl = pickle.load(open(featurePath, \"rb\" )) \n",
    "\n",
    "        runtime = int(movieRuntimeDf.loc[movieList.index(movie)]['effective runtime'])\n",
    "        colourDf = processVisuals(colour, runtime, True)\n",
    "        shadeDf = processVisuals(shade, runtime, False)\n",
    "        audioDf = processAudio(runtime, audio)\n",
    "        sentimentDf = processSubtitles(sentiment,runtime)\n",
    "        aslDf = processASL(asl, runtime)\n",
    "\n",
    "        inputDf = pd.concat([colourDf,shadeDf,audioDf,sentimentDf,aslDf], axis = 1)\n",
    "        movieFeatureDict[movie] = inputDf\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO2\n"
     ]
    }
   ],
   "source": [
    "voc2015Col = vocRounding(voc2015DfAll)\n",
    "voc2013Col = vocRounding(voc2013DfAll)\n",
    "voc2013Df = copy.deepcopy(voc2013DfAll)\n",
    "voc2015Df = copy.deepcopy(voc2015DfAll)\n",
    "voc2013Df.columns = voc2013Col\n",
    "voc2015Df.columns = voc2015Col\n",
    "\n",
    "vocUseList = list()\n",
    "\n",
    "for vocIndex in range(0, len(voc2015Df.columns)):\n",
    "    voc = voc2015Df.columns[vocIndex]\n",
    "    if voc == 'Time':\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            indexMask = list(voc2013Df.columns).index(voc)\n",
    "        except ValueError: #the voc isnt within the 2013 VOC dataset\n",
    "            continue \n",
    "            \n",
    "        print(voc)\n",
    "        #create normal voc screening list\n",
    "        vocDf2013 = voc2013Df.iloc[:,[indexMask]]\n",
    "        vocDf2015 = voc2015Df.iloc[:,[vocIndex]]   \n",
    "        \n",
    "        #generate screenings\n",
    "        screeningList = generateVOCScreenings(vocDf2013,vocDf2015, sliceDict['sliceDf'], sliceDict['matchedMovies'])\n",
    "        matchedMovies = copy.deepcopy(sliceDict['matchedMovies'])\n",
    "        #remove normal screenings with NaN values in the screenings\n",
    "        screeningList, randomisedScreeningList, matchedMovies = removeNaNScreenings(screeningList, screeningList, matchedMovies)\n",
    "        #normalise both screenings \n",
    "        screeningList = normalisation(screeningList, voc)\n",
    "        #create randomised and unrandomised list\n",
    "        vocDict = {'screenings':screeningList, 'matchedMovies':matchedMovies}\n",
    "        #remove all screenings of im off then and help i shrunk the teacher as at the current time do not have the movies\n",
    "        vocDict = removeMovies(vocDict)\n",
    "        \n",
    "        #create overall label and feature df\n",
    "        for i in range(0, len(vocDict['screenings'])): \n",
    "\n",
    "            matchedMovie = vocDict['matchedMovies'][i]\n",
    "\n",
    "            if not(deltaVOCs):\n",
    "                featureDf = pd.concat([featureDf, movieFeatureDict[matchedMovie]])\n",
    "\n",
    "            if not(windowedVOCs):\n",
    "                screening = vocDict['screenings'][i]\n",
    "                labelDf = pd.concat([labelDf, screening['CO2']])\n",
    "\n",
    "        #relabel column title \n",
    "        if not(windowedVOCs):\n",
    "            labelDf.columns = ['VOC']\n",
    "\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21085\n",
      "(21085, 1)\n"
     ]
    }
   ],
   "source": [
    "print(featureDf.shape[0])\n",
    "print(labelDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDRegressor()\n",
    "rmseList = list()\n",
    "for instanceIndex in range(0, labelDf.shape[0]):\n",
    "    instance = (featureDf.iloc[instanceIndex].values).reshape(1, -1)\n",
    "    label = (labelDf.iloc[instanceIndex].values).reshape(-1, 1)\n",
    "    if instanceIndex == 0:\n",
    "        #train the model\n",
    "        clf.fit(instance,label)\n",
    "    else:\n",
    "        #test the model\n",
    "        predicted = clf.predict(instance)\n",
    "        print(predicted)\n",
    "        #get rmse\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(label, predicted))\n",
    "        rmseList.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDf = pd.DataFrame(rmseList,columns=['RMSE'])\n",
    "resultsPath = str(voc) + '_SGD.csv'\n",
    "resultsDf.to_csv(resultsPath, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
