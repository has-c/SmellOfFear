{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import trunc\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and save the feature/label dataframes and save into a dictionary\n",
    "def loadFeaturesLabels():\n",
    "    \n",
    "    #read all the feature-label csvs\n",
    "    #read in files and sort into dictionary\n",
    "    #each element of dict is a movie that contains a list of featurelabel screenings\n",
    "    files = np.sort(os.listdir(\"disk/Features & Label Csvs/\"))\n",
    "    prevMovieName = files[1][:files[1].find(\"_\")]\n",
    "    screeningDict = dict()\n",
    "    screenings = list()\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        if file == '.ipynb_checkpoints':\n",
    "            continue \n",
    "\n",
    "        movieName = file[:file.find(\"_\")]\n",
    "        if movieName != prevMovieName:\n",
    "            screeningDict[prevMovieName] = screenings\n",
    "            screenings = list()\n",
    "            prevMovieName = movieName\n",
    "        else:\n",
    "            infoDf = pd.read_csv(\"disk/Features & Label Csvs/\" + file)\n",
    "            infoDf.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "            infoDf.rename(columns={\"0\": \"VOC\"}, inplace=True)\n",
    "            screenings.append(infoDf)\n",
    "            prevMovieName = movieName\n",
    "    \n",
    "    screeningDict[movieName] = screenings\n",
    "        \n",
    "    return screeningDict\n",
    "\n",
    "\n",
    "#singular features \n",
    "def assembleFeatureLabelDf(screeningDict, movieList):\n",
    "    #assemble entire feature label dataframe \n",
    "    infoDf = pd.DataFrame([])\n",
    "    for movie in movieList:\n",
    "        #access movie \n",
    "        screeningList = screeningDict[movie]\n",
    "        for screening in screeningList:\n",
    "            infoDf = pd.concat([infoDf,screening], axis=0, ignore_index=True)\n",
    "            \n",
    "    return infoDf\n",
    "\n",
    "\n",
    "#window size = 5 mins - 10 instances \n",
    "def createWindowedFeatures(screeningDict, movieList):\n",
    "    #create header for the windowed dataframe\n",
    "    #naming convention Red 1_2 \n",
    "    #Red - colour Red\n",
    "    #1 - position within \n",
    "    singleFeatureHeader = list(screeningDict['Buddy'][0].drop([\"Delta\", \"VOC\"], axis=1).columns)\n",
    "    windowedFeatureHeader = list()\n",
    "    for iteration in range(1,11):\n",
    "        header = [label + \"_\" + str(iteration) for label in singleFeatureHeader]\n",
    "        windowedFeatureHeader += header\n",
    "        \n",
    "    windowedFeatureHeader += [\"Delta\"]\n",
    "\n",
    "    #create windowed features \n",
    "    for movie in movieList:\n",
    "\n",
    "        for screeningIndex in range(0, len(screeningDict[movie])):\n",
    "\n",
    "            screening = screeningDict[movie][screeningIndex]\n",
    "            windowedScreening = pd.DataFrame([])\n",
    "            #create windowed features\n",
    "            for index in range(10, screening.shape[0]):\n",
    "\n",
    "                window = screening[index-10:index].drop([\"Delta\", \"VOC\"], axis=1) #extract window\n",
    "                window = window.values.ravel() #flattened window \n",
    "\n",
    "                #create windowed dataframe\n",
    "                windowedScreening = pd.concat([windowedScreening,pd.DataFrame(np.expand_dims(window, axis=1).T)], axis=0) \n",
    "            \n",
    "            #reindex the windowed screening\n",
    "            windowedScreening.index = range(0, windowedScreening.shape[0])\n",
    "            #add the delta field \n",
    "            delta = pd.DataFrame(np.expand_dims(screening[\"Delta\"][10:].values, axis=1), columns=['Delta'])\n",
    "            windowedScreening = pd.concat([windowedScreening, delta], axis=1, ignore_index=True)   \n",
    "\n",
    "            #add header to dataframe\n",
    "            windowedScreening.columns = windowedFeatureHeader\n",
    "            #assign screening to dict\n",
    "            screeningDict[movie][screeningIndex] = windowedScreening\n",
    "\n",
    "    return screeningDict\n",
    "\n",
    "def dropDuplicateRows(screeningDict):\n",
    "    \n",
    "    #create indices to check repeated rows\n",
    "    movieList = list(screeningDict.keys())\n",
    "\n",
    "    for movie in movieList:\n",
    "\n",
    "        for index in range(0, len(screeningDict[movie])):\n",
    "\n",
    "            screening = screeningDict[movie][index]\n",
    "            \n",
    "            #drop duplicates\n",
    "            screening = screening.drop_duplicates()\n",
    "            #reindex rows\n",
    "            screening.index = range(0, screening.shape[0])\n",
    "\n",
    "            #construct the list \n",
    "            screeningDict[movie][index] = screening\n",
    "            \n",
    "    return screeningDict\n",
    "\n",
    "def calculateDelta(screeningDict):\n",
    "    \n",
    "    movieList = list(screeningDict.keys())\n",
    "    \n",
    "    for movie in movieList:\n",
    "        \n",
    "        for screeningIndex in range(0, len(screeningDict[movie])):\n",
    "            \n",
    "            screening = screeningDict[movie][screeningIndex]\n",
    "    \n",
    "            vocLabels = screening['VOC']\n",
    "            deltaList = list()\n",
    "\n",
    "            delta = None\n",
    "\n",
    "            for index in range(1, vocLabels.shape[0]): \n",
    "                delta = vocLabels.loc[index] - vocLabels.loc[index-1]\n",
    "                deltaList.append(delta)\n",
    "\n",
    "            \n",
    "            #add delta field to dataframe and then assign screening to overall dict\n",
    "            screening.drop(0, axis=0, inplace=True) #drop the first row \n",
    "            screening.index = range(0, screening.shape[0]) #reindex so the join is proper\n",
    "            screening = pd.concat([pd.DataFrame(deltaList, columns=['Delta']),screening], axis=1)\n",
    "            screeningDict[movie][screeningIndex] = screening\n",
    "\n",
    "\n",
    "    return screeningDict\n",
    "\n",
    "def scaleDeltas(screeningDict):\n",
    "    \n",
    "    #scale delta between 0 and 1\n",
    "    movieList = list(screeningDict.keys())\n",
    "\n",
    "    for movie in movieList:\n",
    "        for screeningIndex in range(0, len(screeningDict[movie])):\n",
    "            #access screening\n",
    "            screening = screeningDict[movie][screeningIndex]\n",
    "\n",
    "            #drop na rows\n",
    "            screening.dropna(inplace=True)\n",
    "\n",
    "            #scale\n",
    "            sc = MinMaxScaler()\n",
    "            delta = sc.fit_transform(screening['Delta'].values.reshape(-1,1))\n",
    "            screeningDict[movie][screeningIndex]['Delta'] = delta #assign scaled voc \n",
    "            \n",
    "    return screeningDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the screenings\n",
    "screeningDict = loadFeaturesLabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all duplicated rows \n",
    "screeningDict = dropDuplicateRows(screeningDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate deltas\n",
    "screeningDict = calculateDelta(screeningDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale deltas\n",
    "screeningDict = scaleDeltas(screeningDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create windowed features\n",
    "screeningDict = createWindowedFeatures(screeningDict, list(screeningDict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R2_score = list()\n",
    "RMSE_score = list()\n",
    "testingMovies = list()\n",
    "Random_R2_score = list()\n",
    "Random_RMSE_score = list()\n",
    "\n",
    "movieRuntimesPath = 'Numerical Data/movie_runtimes.csv'\n",
    "movieRuntimeDf = pd.read_csv(movieRuntimesPath, usecols = ['movie', 'runtime (mins)', 'effective runtime'])\n",
    "movieList = list(movieRuntimeDf['movie'])\n",
    "\n",
    "for movie in movieList: \n",
    "    \n",
    "    #train test split \n",
    "    trainingMovies = list(movieRuntimeDf['movie'])\n",
    "    testMovie = [movie]\n",
    "    trainingMovies.pop(trainingMovies.index(testMovie[0]))\n",
    "    \n",
    "    #assemble the training and test feature label dataframes\n",
    "    trainingDf = assembleFeatureLabelDf(screeningDict,trainingMovies)\n",
    "    testingDf = assembleFeatureLabelDf(screeningDict,testMovie)\n",
    "    \n",
    "    featureColName = \"Delta\"\n",
    "    \n",
    "    #NORMAL\n",
    "    #split into labels and features \n",
    "    trainingLabels = trainingDf[featureColName].values\n",
    "    trainingFeatures = trainingDf.drop(featureColName, axis=1).values\n",
    "    testingLabels = testingDf[featureColName].values\n",
    "    testingFeatures = testingDf.drop(featureColName, axis=1).values\n",
    "    #normal \n",
    "    regressor = xgb.XGBRegressor(n_estimators=1000, n_jobs=-1)\n",
    "    regressor.fit(trainingFeatures, trainingLabels.ravel())\n",
    "    #predict\n",
    "    predictions = regressor.predict(testingFeatures)\n",
    "    r2_score = metrics.r2_score(testingLabels, predictions)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(testingLabels,predictions))\n",
    "    #print and save\n",
    "    print(\"R2 score:\", r2_score)\n",
    "    print(\"RMSE: \", rmse)\n",
    "    R2_score.append(r2_score)\n",
    "    RMSE_score.append(rmse)\n",
    "    testingMovies.append(movie)\n",
    "    \n",
    "    #RANDOM\n",
    "    #randomize\n",
    "    \n",
    "#     randomTrainingVOC = copy.deepcopy(trainingDf[featureColName])\n",
    "#     np.random.shuffle(randomTrainingVOC)\n",
    "#     randomTrainingDf = trainingDf.drop(featureColName, axis=1)\n",
    "#     randomTrainingDf = pd.concat([randomTrainingDf,randomTrainingVOC], axis=1)\n",
    "    \n",
    "#     randomTestingVOC = copy.deepcopy(testingDf[featureColName])\n",
    "#     np.random.shuffle(randomTestingVOC)\n",
    "#     randomTestingDf = testingDf.drop(featureColName, axis=1)\n",
    "#     randomTestingDf = pd.concat([randomTestingDf,randomTestingVOC], axis=1)\n",
    "    \n",
    "#     #split into labels and features \n",
    "#     trainingLabels = randomTrainingDf[featureColName].values\n",
    "#     trainingFeatures = randomTrainingDf.drop(featureColName, axis=1).values\n",
    "#     testingLabels = randomTestingDf[featureColName].values\n",
    "#     testingFeatures = randomTestingDf.drop(featureColName, axis=1).values\n",
    "    \n",
    "#     #normal \n",
    "#     regressor = xgb.XGBRegressor(n_estimators=1000, n_jobs=-1)\n",
    "#     regressor.fit(trainingFeatures, trainingLabels.ravel())\n",
    "#     #predict\n",
    "#     predictions = regressor.predict(testingFeatures)\n",
    "#     r2_score = metrics.r2_score(testingLabels, predictions)\n",
    "#     rmse = np.sqrt(metrics.mean_squared_error(testingLabels,predictions))\n",
    "#     #print and save\n",
    "#     print(\"Random R2 score:\", r2_score)\n",
    "#     print(\"Random RMSE: \", rmse)\n",
    "#     Random_R2_score.append(r2_score)\n",
    "#     Random_RMSE_score.append(rmse)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to dataframe\n",
    "pd.DataFrame({'RMSE':RMSE_score, \n",
    "              'R2 Score':R2_score, \n",
    "              'Random RMSE': Random_RMSE_score,\n",
    "              'Random R2 Score':Random_R2_score,\n",
    "              'Test Movie': testingMovies}).to_csv(\"XGBoost Movie and AR Features Randomisation Results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
