{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtitle Sentiment Analysis\n",
    "\n",
    "Using CoreNLP and a StanfordNLP server to perform sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "import logging\n",
    "import json\n",
    "from datetime import time\n",
    "\n",
    "from os import listdir, environ\n",
    "import pickle\n",
    "\n",
    "from subtitle_parsing import denoiseSubtitleSpecificProcessing,subtitlePreprocess\n",
    "import string\n",
    "\n",
    "from google.cloud import translate_v2 as translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"Smell Of Fear-f8e3e23fa7d3.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawSub - subtitles, runtime is the effective runtime \n",
    "def divideSubsIntoSegments(lines, runtime):\n",
    "    \n",
    "    refEndSec = 30\n",
    "    refEndMin = 0\n",
    "    refEndHour = 0\n",
    "    referenceEndTime = time(refEndHour, refEndMin, refEndSec)\n",
    "    refStartSec = 0\n",
    "    refStartMin = 0\n",
    "    refStartHour = 0\n",
    "    referenceStartTime = time(refStartHour, refStartMin, refStartSec)\n",
    "    startTime = None\n",
    "    \n",
    "    subtitleIntervals = list()\n",
    "    \n",
    "    for segment in range(0, runtime):\n",
    "        #parse of timing information\n",
    "        subtitleSegment = list()\n",
    "        for rowIndex in range(0,len(lines)):\n",
    "            line = str(lines[rowIndex])\n",
    "            if len(line) > 15:\n",
    "                arrow = line[13] + line[14] + line[15]\n",
    "                if arrow == '-->':\n",
    "                    #timing information detected\n",
    "                    #parse the actual time\n",
    "                    startTime = line[0:8] #extract the start time\n",
    "                    startHour = int(startTime[0] + startTime[1])\n",
    "                    startMinutes = int(startTime[3] + startTime[4])\n",
    "                    startSeconds = int(startTime[6] + startTime[7])\n",
    "                    startTime = time(startHour,startMinutes,startSeconds)\n",
    "                    \n",
    "                    if startTime > referenceEndTime:\n",
    "                        \n",
    "                        subtitleIntervals.append(subtitleSegment)\n",
    "                        \n",
    "                        refStartSec = refStartSec + 30\n",
    "                        if refStartSec == 60:\n",
    "                            refStartSec = 0\n",
    "                            refStartMin = refStartMin + 1\n",
    "                        if refStartMin == 60:\n",
    "                            refStartMin = 0\n",
    "                            refStartHour = refStartHour + 1\n",
    "                        \n",
    "                        refEndSec = refEndSec + 30\n",
    "                        if refEndSec == 60:\n",
    "                            refEndMin = refEndMin + 1\n",
    "                            refEndSec = 0\n",
    "                        if refEndMin == 60:\n",
    "                            refEndHour = refEndHour + 1\n",
    "                            refEndMin = 0\n",
    "                            \n",
    "                        referenceEndTime = time(refEndHour, refEndMin, refEndSec)\n",
    "                        referenceStartTime = time(refStartHour, refStartMin, refStartSec)\n",
    "                        \n",
    "                        break\n",
    "                        \n",
    "                    continue\n",
    "                    \n",
    "            if startTime != None:\n",
    "                if startTime >= referenceStartTime and startTime <= referenceEndTime:\n",
    "                    subtitleSegment.append(line)   \n",
    "\n",
    "    return subtitleIntervals            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtitle translation\n",
    "def translation_processing(translatedSubs):\n",
    "    \n",
    "    #remove all unecessary characters from the translated text\n",
    "    #loop through each segement and each dialog from within each segment\n",
    "    engTranslated = list()\n",
    "    for i in range(0, len(translatedSubs)):\n",
    "        dialog=translatedSubs[i]\n",
    "        #parse the dialog for weird html characters\n",
    "        k = 0\n",
    "        while True:\n",
    "            try:\n",
    "                if dialog[k] == '&':\n",
    "                    index = dialog.index(';')\n",
    "                    #split off special ascii character\n",
    "                    asciiChr = dialog[k:index+1]\n",
    "                    if asciiChr == '&#39;':\n",
    "                        dialog = dialog[:k] + '\\'' + dialog[index+1:]\n",
    "                    elif asciiChr == '&quot;':\n",
    "                        dialog = dialog[:k] + '\\\"' + dialog[index+1:]\n",
    "                k = k + 1\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        engTranslated.append(dialog)\n",
    "\n",
    "    return engTranslated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import srt files\n",
    "movieRuntimePath = 'data/mounted/Numerical Data/movieRuntimes.csv'\n",
    "movieRuntimeDf = pd.read_csv(movieRuntimePath, usecols = ['movie', 'effective runtime'])\n",
    "movieList = list(movieRuntimeDf['movie'])\n",
    "\n",
    "try:\n",
    "    rawSubtitles = dict()\n",
    "    for movie in movieList:\n",
    "        subPath = 'data/mounted/Features/Subtitles SRT/' + movie + '.srt'\n",
    "        subs = open(subPath, mode = 'r', encoding='utf-8-sig')\n",
    "        rawSubtitles[movie] = subs\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess subtitles\n",
    "movieSubtitles = dict()\n",
    "for movie in movieList:\n",
    "    \n",
    "    #read in subtitles\n",
    "    lines = rawSubtitles[movie].readlines() #contains each line within the document\n",
    "    movieIndex = movieList.index(movie)\n",
    "    #divide into 30 seconds segment\n",
    "    segmentList = divideSubsIntoSegments(lines, movieRuntimeDf['effective runtime'][movieIndex])\n",
    "    \n",
    "    #denoise and normalise the subtitles\n",
    "    parsedSegments = denoiseSubtitleSpecificProcessing(segmentList)\n",
    "    \n",
    "    #translate subtitles if required to\n",
    "    if movie == 'Buddy' or movie == 'Suck Me Shakespeer' or movie == 'Help, I Shrunk My Teacher':\n",
    "        #movie has german subtitles and thus must be translated segment by segment \n",
    "        translate_client = translate.Client()\n",
    "        translatedSegments = list() \n",
    "        for segment in parsedSegments:\n",
    "            # Translates some text from german to english\n",
    "            translation = translate_client.translate(segment, target_language='en')\n",
    "            translatedSegments.append(translation['translatedText'])\n",
    "        \n",
    "        #process the translation and remove any weird chars\n",
    "        parsedSegments = translation_processing(translatedSegments)\n",
    " \n",
    "    #process subtitles\n",
    "    processedSegments = subtitlePreprocess(parsedSegments)\n",
    "    \n",
    "    \n",
    "    passages = list()\n",
    "    #convert lemmized segments to sentences again\n",
    "    for segment in processedSegments:\n",
    "        sentence = str()\n",
    "        for word in segment:\n",
    "            sentence +=  \" \" + word\n",
    "        \n",
    "        passages.append(sentence.strip()) \n",
    "    \n",
    "    movieSubtitles[movie] = passages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run NLP Server\n",
    "\n",
    "Navigate to the directory that contains StanfordNLP then run the following code on Terminal:\n",
    "\n",
    "## Run the server in English\n",
    "java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators \"sentiment\" -port 9000 -timeout 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start the english server and run this\n",
    "subtitleSentiment = dict()\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "for movie in movieList:\n",
    "\n",
    "        subs  = movieSubtitles[movie]\n",
    "        sentiment = list()\n",
    "        sentimentValue = list()\n",
    "        #run each line through core nlp server\n",
    "        for line in subs:\n",
    "            res = nlp.annotate(line, properties={'annotators': 'sentiment','outputFormat': 'json','timeout': 30000,})\n",
    "            if len(line) > 0:\n",
    "                #if line is not empty\n",
    "                sentiment.append(res['sentences'][0]['sentiment'])\n",
    "                sentimentValue.append(res['sentences'][0]['sentimentValue'])\n",
    "            else:\n",
    "                #if line is empty \n",
    "                sentiment.append('Neutral')\n",
    "                sentimentValue.append(2)\n",
    "                        \n",
    "\n",
    "        subtitleSentiment[movie] = pd.DataFrame({'sentiment':sentiment,\n",
    "                                            'sentiment value':sentimentValue})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out the dataframe\n",
    "for movie in movieList:\n",
    "    subs= subtitleSentiment[movie]\n",
    "    subs.to_csv('Sentiment/'+movie+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
