{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Feature Extraction\n",
    " \n",
    "## Extract various features from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import librosa.display\n",
    "import librosa\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv data files\n",
    "movieRuntimePath = 'Numerical Data//movie_runtimes.csv'\n",
    "movieRuntimeDf = pd.read_csv(movieRuntimePath, usecols = ['movie', 'runtime (mins)', 'effective runtime'], header = 0)\n",
    "#create a list of movies\n",
    "movieList = list(movieRuntimeDf['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the raw audio pickle objects\n",
    "\n",
    "sr = 22050 #sampling rate \n",
    "\n",
    "rawAudio = dict()\n",
    "for movie in movieList:\n",
    "    try:\n",
    "        basePath = 'Pickle Objects//Raw Audio File Pickle Objects//'\n",
    "        moviePath = basePath + movie + '.p'\n",
    "        rawAudio[movie] = pickle.load(open(moviePath,\"rb\"))\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features \n",
    "audioFeatures = dict()\n",
    "\n",
    "for movie in movieList:\n",
    "    try:\n",
    "        index = movieList.index(movie)\n",
    "        y = rawAudio[movie]\n",
    "    except: \n",
    "        continue\n",
    "        \n",
    "    #split original dataset y into smaller datasets that correspond to the 30s intervals\n",
    "    runtime = movieRuntimeDf.loc[index]['runtime (mins)'] \n",
    "    intervals = runtime * 2\n",
    "    x = np.array_split(y,intervals)\n",
    "\n",
    "    featureDict = dict()\n",
    "    logMelList = list()\n",
    "    chromaList = list()\n",
    "    tempoList = list()\n",
    "    mfccList = list()\n",
    "    specCentroidList = list()\n",
    "    specContrastList = list()\n",
    "    tonnetzList = list()\n",
    "\n",
    "    for k in x:\n",
    "\n",
    "        #mel power spectrogram\n",
    "        mel = librosa.feature.melspectrogram(y=k,sr=sr)\n",
    "        #convert to log scale (dB) and use peak power as a reference\n",
    "        logMel = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "        #chroma - pitch class information\n",
    "        chroma = librosa.feature.chroma_cqt(y = k, sr=sr)\n",
    "\n",
    "        #estimated tempo information\n",
    "        tempo, beat_frames = librosa.beat.beat_track(y = k,sr=sr)\n",
    "\n",
    "        #mfcc \n",
    "        mfcc = librosa.feature.mfcc(y=k, sr=sr, n_mfcc = 40) #40 is the amount of cepstral vectors \n",
    "\n",
    "        #spectral centroid - relates to brightness of sound\n",
    "        specCentroid = librosa.feature.spectral_centroid(y = k, sr=sr)\n",
    "\n",
    "        #spectral contrast\n",
    "        specContrast = librosa.feature.spectral_contrast(y = k, sr=sr)\n",
    "\n",
    "        #tonnetz - tonal centroid features\n",
    "        tonnetz = librosa.feature.tonnetz(y = k, sr = sr)\n",
    "\n",
    "        logMelList.append(logMel)\n",
    "        chromaList.append(chroma)\n",
    "        tempoList.append(tempo)\n",
    "        mfccList.append(mfcc)\n",
    "        specCentroidList.append(specCentroid)\n",
    "        specContrastList.append(specContrast)\n",
    "        tonnetzList.append(tonnetz)\n",
    "\n",
    "    featureDict['logMel'] = logMelList\n",
    "    featureDict['chroma'] = chromaList\n",
    "    featureDict['tempo'] = tempoList\n",
    "    featureDict['mfcc'] = mfccList\n",
    "    featureDict['specCentroid'] = specCentroidList\n",
    "    featureDict['specContrast'] = specContrastList\n",
    "    featureDict['tonnetz'] = tonnetzList\n",
    "\n",
    "    audioFeatures[movie] = featureDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audioFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save pickle objects\n",
    "#tried to save the whole audio feature dictionary but memory requirements wont allow it\n",
    "#saving each movie independently\n",
    "for movie in movieList:\n",
    "    try:\n",
    "        audioFeaturePath = 'Pickle Objects//' + movie + '.p'\n",
    "        pickle.dump(audioFeatures[movie], open(audioFeaturePath, \"wb\" ))\n",
    "    except KeyError: \n",
    "        pass #movie hasnt been added to collection yet\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
