{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from RegressionRF import RegressionModel\n",
    "from math import trunc\n",
    "import pickle\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUT FUNCTIONS \n",
    "\n",
    "#vocRounding is used to truncate the VOCs to 3dp allowing for flexible matching between 2013 and 2015 datasets\n",
    "def vocRounding(vocDf):\n",
    "    vocList = list()\n",
    "    for index in range(0, len(vocDf.columns)):\n",
    "        if vocDf.columns[index] == 'Time' or vocDf.columns[index] == 'ocs' or vocDf.columns[index] == 'co' or vocDf.columns[index] == 'CO2':\n",
    "            vocList.append(vocDf.columns[index])    \n",
    "        else:\n",
    "            #string slice to get the molar mass\n",
    "            voc = vocDf.columns[index]\n",
    "            mass = (trunc(float(voc[1:])*1000))/1000 #TRUNCATE TO 3DP\n",
    "            vocList.append(mass)\n",
    "    return vocList\n",
    "\n",
    "#generate normalised screenings\n",
    "#remove invalid screenings (divide by NaN or divide by 0)\n",
    "def generateNormalisedScreenings(sliceDict, vocData):\n",
    "    screeningList = list()\n",
    "    matchedMovies = list()\n",
    "    for index in range(0,sliceDict['sliceDf'].shape[0]):\n",
    "        start,end = sliceDict['sliceDf'].loc[index]\n",
    "        screening = vocData[start:end+1]\n",
    "        normalisedFrame = copy.deepcopy(screening)\n",
    "        if max(normalisedFrame.values) != 0 and not(np.isnan(max(normalisedFrame.values))):\n",
    "            normalisedFrame = normalisedFrame.values/max(normalisedFrame.values)\n",
    "            screeningList.append(normalisedFrame)\n",
    "            matchedMovies.append(sliceDict['matchedMovies'][index])\n",
    "    return screeningList, matchedMovies\n",
    "\n",
    "#stretch or compress screenings for randomisation\n",
    "def stretchCompressScreening(currentScreening,referenceScreening):\n",
    "    #stretch and compress screenings\n",
    "    if len(currentScreening) > len(referenceScreening):\n",
    "        #compression required\n",
    "        #randomly select a certain voc instance and remove it from its position\n",
    "        while len(currentScreening) > len(referenceScreening):\n",
    "            updatedLength = len(currentScreening)\n",
    "            deletePosition = random.randint(0,updatedLength-1) \n",
    "            mask = np.repeat(True, repeats=len(currentScreening))\n",
    "            mask[deletePosition] = False\n",
    "            currentScreening = currentScreening[mask]\n",
    "    else:\n",
    "        #stretch required\n",
    "        #randomly picked a certain voc instance and insert it at the same position effectively doubling it\n",
    "        while len(currentScreening) < len(referenceScreening):\n",
    "            updatedLength = len(currentScreening)\n",
    "            insertPosition = random.randint(0,updatedLength-1)\n",
    "            instance = currentScreening[insertPosition]\n",
    "            currentScreening = np.insert(currentScreening,insertPosition,instance)\n",
    "    \n",
    "    return currentScreening,referenceScreening\n",
    "\n",
    "def randomisation(movieList,screeningList,matchedMovies):\n",
    "    #randomisation using chain swap\n",
    "    randomisedScreenings = np.array([screeningList])[0] #numpy array of screenings\n",
    "\n",
    "    #randomise the movies - #shuffle list of movies to get pairs of movies to swap\n",
    "    randomisedMovieList = np.array(movieList)\n",
    "    np.random.shuffle(randomisedMovieList)\n",
    "    \n",
    "    #setup objects\n",
    "    randomisedScreeningList = list()\n",
    "    randomisedMatchedMovies = list()\n",
    "\n",
    "    #order in which to access the reference movie is set by the referenceMovieIndex\n",
    "    for referenceMovieIndex in list(np.append(np.arange(1,len(movieList))-1,-1)):\n",
    "\n",
    "        referenceMovie = randomisedMovieList[referenceMovieIndex]\n",
    "        modifyMovie = randomisedMovieList[referenceMovieIndex+1] #movie to stretch/compress \n",
    "\n",
    "        #extract reference movie and modify movie screenings \n",
    "        maskReference = np.char.equal(np.array(matchedMovies), referenceMovie)\n",
    "        referenceMovieScreenings = randomisedScreenings[maskReference]\n",
    "        maskModify = np.char.equal(np.array(matchedMovies), modifyMovie)\n",
    "        modifyMovieScreenings = randomisedScreenings[maskModify]\n",
    "\n",
    "        #randomisation engine\n",
    "        for currentScreening in modifyMovieScreenings:\n",
    "\n",
    "            #randomly select a reference screening to assign\n",
    "            referenceScreening = referenceMovieScreenings[np.random.randint(0,len(referenceMovieScreenings))]\n",
    "            #stretch/compress screening\n",
    "            currentScreening,referenceScreening = stretchCompressScreening(currentScreening,referenceScreening)\n",
    "\n",
    "            #add current screening to the overall list \n",
    "            randomisedScreeningList.append(currentScreening)\n",
    "            randomisedMatchedMovies.append(referenceMovie)\n",
    "    \n",
    "    return randomisedMatchedMovies,randomisedScreeningList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT FEATURE FUNCTIONS\n",
    "\n",
    "def grouping(visualList):\n",
    "    framesPerInterval = 30\n",
    "    movieVisuals = list()\n",
    "    for index in range(0, int(len(visualList)/framesPerInterval)):\n",
    "        segment = visualList[index*framesPerInterval:index*framesPerInterval+framesPerInterval]\n",
    "        movieVisuals.append(segment)\n",
    "    return movieVisuals\n",
    "\n",
    "def processVisuals(movieVisualData, runtime, isColour):\n",
    "    visualDataIntervals = grouping(movieVisualData)\n",
    "    #the visual data also has the credits accounted for so remove them\n",
    "    visualDataIntervals = visualDataIntervals[:runtime]\n",
    "    #create a dataframe \n",
    "    if isColour: \n",
    "        #create a dominant colour dataframe\n",
    "        framesPerInterval = 30\n",
    "        header = list();\n",
    "        for i in range(1,framesPerInterval+1):\n",
    "            header = header + ['R'+str(i), 'G' + str(i),  'B'+str(i)]\n",
    "    else: #shade object to be parsed\n",
    "        framesPerInterval = 30\n",
    "        header = ['S' + str(x) for x in range(1,framesPerInterval+1)]\n",
    "    \n",
    "    visualDf = pd.DataFrame(columns=header)\n",
    "    #assemble the dataframe\n",
    "    for segment in visualDataIntervals:\n",
    "        index = visualDataIntervals.index(segment)\n",
    "        colourRow = list()\n",
    "        for colour in segment:\n",
    "            if isColour:\n",
    "                colourRow = colourRow + [colour[0], colour[1], colour[2]]\n",
    "            else:\n",
    "                colourRow = colourRow + [colour[0]]\n",
    "        #assign that colour row to the dataframe\n",
    "        visualDf.loc[index] = colourRow\n",
    "            \n",
    "    return visualDf\n",
    "\n",
    "def processAudio(runtime, audio):\n",
    "    audioFeatures = list(audio.keys())\n",
    "\n",
    "    audioDf = pd.DataFrame(columns=[])        \n",
    "    for key in audioFeatures:\n",
    "        audio[key] = audio[key][:runtime]\n",
    "\n",
    "        #assemble df \n",
    "        #create header\n",
    "        if key != 'tempo':\n",
    "            header = [key + str(x) for x in range(1, len(audio[key][0])+1)]\n",
    "        else:\n",
    "            header = ['tempo']\n",
    "\n",
    "        audioFeatureDf = pd.DataFrame(columns=header)\n",
    "        for index in range(0, len(audio[key])):\n",
    "            feature = audio[key][index]\n",
    "            audioFeatureDf.loc[index] = feature\n",
    "\n",
    "        #concatenate featureDf to audioDf\n",
    "        audioDf = pd.concat([audioDf,audioFeatureDf], axis=1)\n",
    "    \n",
    "    return audioDf\n",
    "\n",
    "def processSubtitles(subs, effectiveRuntime):\n",
    "    \n",
    "    header = ['sentiment value']\n",
    "    subSentimentDf = pd.DataFrame(columns=header)\n",
    "    for sentimentIndex in range(0, len(subs)):\n",
    "        sentiment = subs[sentimentIndex]\n",
    "        if len(sentiment) != 0:\n",
    "            if sentiment['sentimentValue'] == np.NaN:\n",
    "                print('YES')\n",
    "            else:         \n",
    "                subSentimentDf.loc[sentimentIndex] = [sentiment['sentimentValue']]\n",
    "        else:\n",
    "            subSentimentDf.loc[sentimentIndex] = [-1] #indicates no dialog occurred during the scene\n",
    "        \n",
    "        #enforce no dialog until the credit scene if there is in fact no dialog\n",
    "        if len(subSentimentDf) != effectiveRuntime:\n",
    "            #no dialog at the end thus need to fill the rest with -1\n",
    "            for index in range(0, effectiveRuntime-len(subSentimentDf)+1):\n",
    "                 subSentimentDf.loc[index] = [-1]\n",
    "    \n",
    "    return subSentimentDf\n",
    "\n",
    "def processASL(asl, effectiveRuntime):\n",
    "    \n",
    "    header = ['average shot length']\n",
    "    aslDf = pd.DataFrame(columns=header)\n",
    "    for index in range(0, effectiveRuntime): \n",
    "        aslValue = asl[index]\n",
    "        aslDf.loc[index] = aslValue\n",
    "    return aslDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split - one movie is left out for the test set \n",
    "def movieTrainTestSplit(movieList,matchedMovies,screeningList):\n",
    "    \n",
    "    testScreeningList = list()\n",
    "    testMovieList = list()\n",
    "    testMovie = movieList[random.randint(0, len(movieList)-1)] #pick random test movie \n",
    "    while True:\n",
    "        try:\n",
    "            matchedIndex = matchedMovies.index(testMovie)\n",
    "            screening = screeningList.pop(matchedIndex)\n",
    "            testScreeningList.append(screening)\n",
    "            matchedMovie = matchedMovies.pop(matchedIndex)\n",
    "            testMovieList.append(testMovie)\n",
    "        except ValueError:\n",
    "            break\n",
    "    \n",
    "    return testScreeningList,testMovieList,screeningList,matchedMovies\n",
    "\n",
    "\n",
    "#create overall feature label dataframe\n",
    "def inputOutputDf(screeningList,matchedMovies,movieFeatureDict):\n",
    "    \n",
    "    #create input-output df\n",
    "    info = np.array([])\n",
    "    for i in range(0, len(screeningList)): \n",
    "        \n",
    "        matchedMovie = matchedMovies[i]\n",
    "        screening = screeningList[i]    \n",
    "    \n",
    "        #only join movie if the movie screening and the length of the features is the same\n",
    "        if len(movieFeatureDict[matchedMovie]) == len(screening[9:]):\n",
    "            #concatenate the movie features and the vocs \n",
    "            if info.size == 0:\n",
    "                info = np.hstack((movieFeatureDict[matchedMovie].values,np.expand_dims(screening[9:], axis=1)))\n",
    "            else:\n",
    "                info = np.vstack((info,\n",
    "                                 np.hstack((movieFeatureDict[matchedMovie].values,np.expand_dims(screening[9:], axis=1)))))\n",
    "                \n",
    "    \n",
    "    #convert all values inside the dataset to floats\n",
    "    info = info.astype(float)\n",
    "    \n",
    "    return info \n",
    "\n",
    "#regressor \n",
    "def RegressionModel(featuresTrain,labelsTrain, labelsTest):\n",
    "    \n",
    "    regressor = RandomForestRegressor() #random forest will base parameters\n",
    "    regressor.fit(featuresTrain, labelsTrain.values.ravel())\n",
    "    labelsPred = regressor.predict(featuresTest)\n",
    "    \n",
    "    #metrics\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(labelsTest, labelsPred))\n",
    "    MAE = metrics.mean_absolute_error(labelsTest, labelsPred)\n",
    "    R2 = metrics.r2_score(labelsTest, labelsPred)\n",
    "    \n",
    "    return RMSE,MAE,R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE DF\n",
    "\n",
    "#overall feature and labels df\n",
    "featureDf = pd.DataFrame([]) #film feature dataframe\n",
    "labelDf = pd.DataFrame([]) #voc dataframe\n",
    "\n",
    "#import movie runtimes\n",
    "movieRuntimesPath = 'Numerical Data/movie_runtimes.csv'\n",
    "movieRuntimeDf = pd.read_csv(movieRuntimesPath, usecols = ['movie', 'runtime (mins)', 'effective runtime'])\n",
    "movieList = list(movieRuntimeDf['movie'])\n",
    "movieFeatureDict = dict() #dict contains the movie film features with the keys being the movies\n",
    "#import pickle objects for movies and then assemble the dataframes  \n",
    "for movie in movieList:\n",
    "    #load pickle feauture objects\n",
    "    featurePath = 'Pickle Objects/Audio Feature Pickle Objects/' + movie + '.p'\n",
    "    audio = pickle.load(open(featurePath, \"rb\" )) \n",
    "    featurePath = 'Pickle Objects/Colour Pickle Objects/' + movie + '.p'\n",
    "    colour = pickle.load(open(featurePath, \"rb\" )) \n",
    "    featurePath = 'Pickle Objects/Shade Pickle Objects/' + movie + '.p'\n",
    "    shade = pickle.load(open(featurePath, \"rb\" )) \n",
    "    featurePath = 'Pickle Objects/Subtitle Sentiment Pickle Objects/' + movie + '.p'\n",
    "    sentiment = pickle.load(open(featurePath, \"rb\" )) \n",
    "    featurePath = 'Pickle Objects/ASL Pickle Objects/' + movie + '.p'\n",
    "    asl = pickle.load(open(featurePath, \"rb\" )) \n",
    "\n",
    "    runtime = int(movieRuntimeDf.loc[movieList.index(movie)]['effective runtime'])\n",
    "\n",
    "    colourDf = processVisuals(colour, runtime, True)\n",
    "    shadeDf = processVisuals(shade, runtime, False)\n",
    "    audioDf = processAudio(runtime, audio)\n",
    "    sentimentDf = processSubtitles(sentiment,runtime)\n",
    "    aslDf = processASL(asl, runtime)\n",
    "\n",
    "    #add windowing\n",
    "    effectiveRuntime = movieRuntimeDf['effective runtime'][movieList.index(movie)]\n",
    "    movieFeatureArray = np.array([])\n",
    "    for index in range(9, effectiveRuntime):\n",
    "        endIndex = index\n",
    "        startIndex = index - 9\n",
    "        colourWindow = colourDf.loc[startIndex:endIndex,:].values.ravel() #create 1D vector of values\n",
    "        audioWindow = audioDf.loc[startIndex:endIndex,:].values.ravel()\n",
    "        shadeWindow = shadeDf.loc[startIndex:endIndex,:].values.ravel()\n",
    "        sentimentWindow = sentimentDf.loc[startIndex:endIndex,:].values.ravel() \n",
    "        aslWindow = aslDf.loc[startIndex:endIndex,:].values.ravel()\n",
    "        window = np.concatenate([colourWindow, audioWindow, shadeWindow, sentimentWindow,aslWindow])\n",
    "        if len(movieFeatureArray) == 0:\n",
    "            movieFeatureArray = window\n",
    "        else:\n",
    "            movieFeatureArray = np.vstack([movieFeatureArray, window])\n",
    "\n",
    "    movieFeatureDict[movie] = pd.DataFrame(movieFeatureArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE VOC DF\n",
    "\n",
    "#import various numeric csvs\n",
    "vocPath = 'Numerical Data/2013VOCData.csv'\n",
    "voc2013DfAll = pd.read_csv(vocPath, header = 0, nrows = 74208, low_memory=False)\n",
    "movieScreeningsPath = 'Numerical Data/screening_times.csv'\n",
    "movingScreeningsDf = pd.read_csv(movieScreeningsPath, usecols = ['scheduled','movie','filled %'])\n",
    "movieRuntimesPath = 'Numerical Data/movie_runtimes.csv'\n",
    "movieRuntimeDf = pd.read_csv(movieRuntimesPath, usecols = ['movie', 'runtime (mins)', 'effective runtime'])\n",
    "#2015 Dataset\n",
    "starWarsPath = 'Numerical Data/Star Wars-The Force Awakens.csv'\n",
    "starWarsScreeningDf = pd.read_csv(starWarsPath)\n",
    "imOffThenPath = 'Numerical Data/I\\'m Off Then.csv'\n",
    "imOffThenScreeningDf = pd.read_csv(imOffThenPath)\n",
    "helpIShrunkTheTeacherPath = 'Numerical Data/Help, I Shrunk My Teacher.csv'\n",
    "helpIShrunkTheTeacherScreeningDf = pd.read_csv(helpIShrunkTheTeacherPath)\n",
    "vocPath = 'Numerical Data/2015VOCData.csv'\n",
    "voc2015DfAll = pd.read_csv(vocPath)\n",
    "#remove first column of 2015 voc df as its not used\n",
    "voc2015DfAll.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "#full list of movies\n",
    "movieList = list(movieRuntimeDf['movie'])\n",
    "\n",
    "\n",
    "#import the slicing indices\n",
    "slicePath = 'Pickle Objects/VocSlices.p'\n",
    "sliceDict = pickle.load(open(slicePath, \"rb\" )) #contains df of co2 slice indices and matched movie list\n",
    "\n",
    "#round the vocs\n",
    "voc2015Col = vocRounding(voc2015DfAll)\n",
    "voc2013Col = vocRounding(voc2013DfAll)\n",
    "voc2013Df = copy.deepcopy(voc2013DfAll)\n",
    "voc2015Df = copy.deepcopy(voc2015DfAll)\n",
    "voc2013Df.columns = voc2013Col\n",
    "voc2015Df.columns = voc2015Col\n",
    "\n",
    "#rearrange dataframe to be able to merge them successfully\n",
    "voc = voc2015Df.columns[1:]\n",
    "voc2015Df = pd.DataFrame(np.transpose(voc2015Df.values)[1:,:], columns =voc2015Df['Time'])\n",
    "voc2015Df['voc'] = voc\n",
    "voc = index=voc2013Df.columns[1:]\n",
    "voc2013Df = pd.DataFrame(np.transpose(voc2013Df.values)[1:,:], columns =voc2013Df['Time'])\n",
    "voc2013Df['voc'] = voc\n",
    "\n",
    "#join the two voc dataframes (join on the 2013 dataframe)\n",
    "vocDf = pd.merge(voc2013Df, voc2015Df, how='inner', on=['voc'])\n",
    "#drop voc column\n",
    "vocColumn = vocDf['voc']\n",
    "vocDf.drop(\"voc\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#reorientate the vocDf, note need to convert all vocs to float\n",
    "vocDf = pd.DataFrame(np.transpose(vocDf.values.astype(float)), columns=vocColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsList = list()\n",
    "for vocIndex in range(0,vocDf.shape[1]):\n",
    "    \n",
    "    voc = vocDf.columns[vocIndex]\n",
    "    vocData = vocDf[voc]\n",
    "    \n",
    "    #generate normalised screenings\n",
    "    screeningList, matchedMovies = generateNormalisedScreenings(sliceDict, vocData)\n",
    "    \n",
    "    #randomisation\n",
    "    randomisedMatchedMovies,randomisedScreeningList = randomisation(movieList,screeningList,matchedMovies)\n",
    "    \n",
    "    #movie-based train test split\n",
    "    #normal screenings\n",
    "    testScreenings,testMovies,trainScreenings,trainMovies = movieTrainTestSplit(movieList,matchedMovies,screeningList)\n",
    "    #randomisd screnings split\n",
    "    randomisedTestScreenings, randomisedTestMovies, randomisedTrainScreenings, randomisedTrainMovies = \\\n",
    "    movieTrainTestSplit(movieList,randomisedMatchedMovies,randomisedScreeningList)\n",
    "    \n",
    "    #normal input/output df\n",
    "    testSet = inputOutputDf(testScreenings,testMovies,movieFeatureDict)\n",
    "    trainSet = inputOutputDf(trainScreenings,trainMovies,movieFeatureDict)\n",
    "    #randomised input/output df\n",
    "    randomTestSet = inputOutputDf(randomisedTestScreenings,randomisedTestMovies,movieFeatureDict)\n",
    "    randomTrainSet = inputOutputDf(randomisedTrainScreenings,randomisedTrainMovies,movieFeatureDict)\n",
    "    \n",
    "    #extract labels and features\n",
    "    #unrandomised\n",
    "    featuresTrain = trainSet[:, 0:-1]\n",
    "    labelsTrain = trainSet[-1]\n",
    "    featuresTest = testSet[:, 0:-1]\n",
    "    labelsTest = testSet[-1]\n",
    "    #randomised\n",
    "    randomFeaturesTrain = randomTrainSet[:, 0:-1] \n",
    "    randomLabelsTrain = randomTrainSet[-1]\n",
    "    randomFeaturesTest = randomTestSet[:, 0:-1]\n",
    "    randomLabelsTest = randomTestSet[-1]\n",
    "    \n",
    "    #regression\n",
    "    #regressor - unrandomised\n",
    "    RMSE,MAE,R2 = RegressionModel(featuresTrain,labelsTrain, labelsTest)\n",
    "    resultsList.append([False, voc, RMSE,MAE,R2])\n",
    "    RMSE,MAE,R2 = RegressionModel(randomFeaturesTrain,randomLabelsTrain, randomLabelsTest)\n",
    "    resultsList.append([True, voc, RMSE,MAE,R2])\n",
    "    \n",
    "    #create results Df\n",
    "    resultsDf = pd.DataFrame(resultsList,columns=resultsHeader)\n",
    "    #write df to output file\n",
    "    resultsPath = str(voc) + '.csv'\n",
    "    resultsDf.to_csv(resultsPath, sep=',', encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
