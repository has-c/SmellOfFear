{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection: Use Relief and other feature selection methods \n",
    "\n",
    "Check if some features are higher importance than the AR features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReliefF import ReliefF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import trunc\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping(visualList):\n",
    "    framesPerInterval = 30\n",
    "    movieVisuals = list()\n",
    "    for index in range(0, int(len(visualList)/framesPerInterval)):\n",
    "        segment = visualList[index*framesPerInterval:index*framesPerInterval+framesPerInterval]\n",
    "        movieVisuals.append(segment)\n",
    "    return movieVisuals\n",
    "\n",
    "def processVisuals(movieVisualData, runtime, isColour):\n",
    "    visualDataIntervals = grouping(movieVisualData)\n",
    "    #the visual data also has the credits accounted for so remove them\n",
    "    visualDataIntervals = visualDataIntervals[:runtime]\n",
    "    #create a dataframe \n",
    "    if isColour: \n",
    "        #create a dominant colour dataframe\n",
    "        framesPerInterval = 30\n",
    "        header = list();\n",
    "        for i in range(1,framesPerInterval+1):\n",
    "            header = header + ['R'+str(i), 'G' + str(i),  'B'+str(i)]\n",
    "    else: #shade object to be parsed\n",
    "        framesPerInterval = 30\n",
    "        header = ['S' + str(x) for x in range(1,framesPerInterval+1)]\n",
    "    \n",
    "    visualDf = pd.DataFrame(columns=header)\n",
    "    #assemble the dataframe\n",
    "    for segment in visualDataIntervals:\n",
    "        index = visualDataIntervals.index(segment)\n",
    "        colourRow = list()\n",
    "        for colour in segment:\n",
    "            if isColour:\n",
    "                colourRow = colourRow + [colour[0], colour[1], colour[2]]\n",
    "            else:\n",
    "                colourRow = colourRow + [colour[0]]\n",
    "        #assign that colour row to the dataframe\n",
    "        visualDf.loc[index] = colourRow\n",
    "            \n",
    "    return visualDf\n",
    "\n",
    "def processAudio(runtime, audio):\n",
    "    audioFeatures = list(audio.keys())\n",
    "\n",
    "    audioDf = pd.DataFrame(columns=[])        \n",
    "    for key in audioFeatures:\n",
    "        audio[key] = audio[key][:runtime]\n",
    "\n",
    "        #assemble df \n",
    "        #create header\n",
    "        if key != 'tempo':\n",
    "            header = [key + str(x) for x in range(1, len(audio[key][0])+1)]\n",
    "        else:\n",
    "            header = ['tempo']\n",
    "\n",
    "        audioFeatureDf = pd.DataFrame(columns=header)\n",
    "        for index in range(0, len(audio[key])):\n",
    "            feature = audio[key][index]\n",
    "            audioFeatureDf.loc[index] = feature\n",
    "\n",
    "        #concatenate featureDf to audioDf\n",
    "        audioDf = pd.concat([audioDf,audioFeatureDf], axis=1)\n",
    "    \n",
    "    return audioDf\n",
    "\n",
    "def processSubtitles(subs, effectiveRuntime):\n",
    "    \n",
    "    header = ['sentiment value']\n",
    "    subSentimentDf = pd.DataFrame(columns=header)\n",
    "    for sentimentIndex in range(0, len(subs)):\n",
    "        sentiment = subs[sentimentIndex]\n",
    "        if len(sentiment) != 0:\n",
    "            if sentiment['sentimentValue'] == np.NaN:\n",
    "                print('YES')\n",
    "            else:         \n",
    "                subSentimentDf.loc[sentimentIndex] = [sentiment['sentimentValue']]\n",
    "        else:\n",
    "            subSentimentDf.loc[sentimentIndex] = [-1] #indicates no dialog occurred during the scene\n",
    "        \n",
    "        #enforce no dialog until the credit scene if there is in fact no dialog\n",
    "        if len(subSentimentDf) != effectiveRuntime:\n",
    "            #no dialog at the end thus need to fill the rest with -1\n",
    "            for index in range(0, effectiveRuntime-len(subSentimentDf)+1):\n",
    "                 subSentimentDf.loc[index] = [-1]\n",
    "    \n",
    "    return subSentimentDf\n",
    "\n",
    "def processASL(asl, effectiveRuntime):\n",
    "    \n",
    "    header = ['average shot length']\n",
    "    aslDf = pd.DataFrame(columns=header)\n",
    "    for index in range(0, effectiveRuntime): \n",
    "        aslValue = asl[index]\n",
    "        aslDf.loc[index] = aslValue\n",
    "    return aslDf\n",
    "\n",
    "\n",
    "#vocRounding is used to truncate the VOCs to 3dp allowing for flexible matching between 2013 and 2015 datasets\n",
    "def vocRounding(vocDf):\n",
    "    vocList = list()\n",
    "    for index in range(0, len(vocDf.columns)):\n",
    "        if vocDf.columns[index] == 'Time' or vocDf.columns[index] == 'ocs' or vocDf.columns[index] == 'co' or vocDf.columns[index] == 'CO2':\n",
    "            vocList.append(vocDf.columns[index])    \n",
    "        else:\n",
    "            #string slice to get the molar mass\n",
    "            voc = vocDf.columns[index]\n",
    "            mass = (trunc(float(voc[1:])*1000))/1000 #TRUNCATE TO 3DP\n",
    "            vocList.append(mass)\n",
    "    return vocList\n",
    "\n",
    "#generate normalised screenings\n",
    "#remove invalid screenings (divide by NaN or divide by 0)\n",
    "#scale vocs between 0 and 1\n",
    "def generateNormalisedScreenings(sliceDict, vocData):\n",
    "    screeningList = list()\n",
    "    matchedMovies = list()\n",
    "    for index in range(0,sliceDict['sliceDf'].shape[0]):\n",
    "        start,end = sliceDict['sliceDf'].loc[index]\n",
    "        screening = vocData[start:end+1]\n",
    "        normalisedFrame = copy.deepcopy(screening)\n",
    "        if max(normalisedFrame.values) != 0 and not(np.isnan(max(normalisedFrame.values))):\n",
    "            normalisedFrame = normalisedFrame.values.reshape(-1,1)\n",
    "            scaler = MinMaxScaler()\n",
    "            normalisedFrame = scaler.fit_transform(normalisedFrame)\n",
    "            normalisedFrame = np.transpose(normalisedFrame)\n",
    "            screeningList.append(normalisedFrame)\n",
    "            matchedMovies.append(sliceDict['matchedMovies'][index])\n",
    "    return screeningList, matchedMovies\n",
    "\n",
    "#train test split - one movie is left out for the test set \n",
    "def movieTrainTestSplit(movieList,matchedMovies,screeningList):\n",
    "    \n",
    "    testScreeningList = list()\n",
    "    testMovieList = list()\n",
    "    testMovie = movieList[random.randint(0, len(movieList)-1)] #pick random test movie \n",
    "    while True:\n",
    "        try:\n",
    "            matchedIndex = matchedMovies.index(testMovie)\n",
    "            screening = screeningList.pop(matchedIndex)\n",
    "            testScreeningList.append(screening)\n",
    "            matchedMovie = matchedMovies.pop(matchedIndex)\n",
    "            testMovieList.append(testMovie)\n",
    "        except ValueError:\n",
    "            break\n",
    "    \n",
    "    return testScreeningList,testMovieList,screeningList,matchedMovies\n",
    "\n",
    "#create overall feature label dataframe\n",
    "def inputOutputDf(screeningList,matchedMovies,movieFeatureDict):\n",
    "    \n",
    "    #create input-output df\n",
    "    info = np.array([])\n",
    "    for i in range(0, len(screeningList)): \n",
    "        \n",
    "        \n",
    "        matchedMovie = matchedMovies[i]\n",
    "        screening = screeningList[i]  \n",
    "        \n",
    "        #Calculate deltas\n",
    "        percentageChange = np.array([(screening[0,x+1] - screening[0,x])/screening[0,x] for x in range(8,screening.shape[1]-1)])\n",
    "        percentageChange[np.isinf(percentageChange)] = 0\n",
    "        #get categorical values\n",
    "        # 1 up\n",
    "        # 0 no change\n",
    "        # -1 down\n",
    "        outputLabels = categoricalValues(percentageChange)\n",
    "        \n",
    "        #AR VOC Input\n",
    "        screening = screening[0] #remove the 1st dimension\n",
    "        listOfInstances = [screening[x:x+9] for x in range(0,len(screening))]\n",
    "        inputDf = np.array([])\n",
    "        for instance in listOfInstances:\n",
    "            if len(instance) == 9:\n",
    "                if inputDf.size == 0:\n",
    "                    inputDf = instance\n",
    "                else:\n",
    "                    inputDf = np.vstack((inputDf,instance))\n",
    "        #cut off last row (as cannot predict it)\n",
    "        inputDf = inputDf[:-1]\n",
    "        \n",
    "\n",
    "        \n",
    "        #only join movie if the movie screening and the length of the features is the same\n",
    "        #concatenate the movie features and the vocs \n",
    "        if inputDf.shape[0] == movieFeatureDict[matchedMovie].values.shape[0]:\n",
    "            if info.size == 0:\n",
    "                features = np.hstack((inputDf,movieFeatureDict[matchedMovie].values))\n",
    "                info = np.hstack((features,np.expand_dims(outputLabels, axis=1)))\n",
    "            else:\n",
    "                features = np.hstack((inputDf,movieFeatureDict[matchedMovie].values))\n",
    "                info = np.vstack((info,\n",
    "                                 np.hstack((features,np.expand_dims(outputLabels, axis=1)))))\n",
    "                \n",
    "    #convert all values inside the dataset to floats\n",
    "    info = info.astype(float)\n",
    "    \n",
    "    return info \n",
    "\n",
    "def categoricalValues(percentageChange):\n",
    "\n",
    "    percentageChangeFlatUpperLimit = 0.02\n",
    "    percentageChangeFlatLowerLimit = -0.02\n",
    "    # calculate percetange change between 2 values to get the output label\n",
    "    #categories - 'no change', 'up', 'down'\n",
    "    #up = 1\n",
    "    #down = -1\n",
    "    #no change = 0\n",
    "\n",
    "    outputLabels = np.zeros(percentageChange.shape[0])\n",
    "    #up category\n",
    "    upMask = np.greater_equal(percentageChange, percentageChangeFlatUpperLimit)\n",
    "    outputLabels[upMask] = 1\n",
    "    #down category\n",
    "    downMask = np.less_equal(percentageChange, percentageChangeFlatLowerLimit)\n",
    "    outputLabels[downMask] = -1\n",
    "    \n",
    "    return outputLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Loaded\n",
      "Labels loaded\n"
     ]
    }
   ],
   "source": [
    "#overall feature and labels df\n",
    "featureDf = pd.DataFrame([]) #film feature dataframe\n",
    "labelDf = pd.DataFrame([]) #voc dataframe\n",
    "\n",
    "#import movie runtimes\n",
    "movieRuntimesPath = 'Numerical Data/movie_runtimes.csv'\n",
    "movieRuntimeDf = pd.read_csv(movieRuntimesPath, usecols = ['movie', 'runtime (mins)', 'effective runtime'])\n",
    "movieList = list(movieRuntimeDf['movie'])\n",
    "movieFeatureDict = dict() #dict contains the movie film features with the keys being the movies\n",
    "#import pickle objects for movies and then assemble the dataframes  \n",
    "for movie in movieList:\n",
    "    #load pickle feauture objects\n",
    "    featurePath = 'Pickle Objects/Audio Feature Pickle Objects/' + movie + '.p'\n",
    "    audio = pickle.load(open(featurePath, \"rb\" )) \n",
    "    featurePath = 'Pickle Objects/Colour Pickle Objects/' + movie + '.p'\n",
    "    colour = pickle.load(open(featurePath, \"rb\" )) \n",
    "    featurePath = 'Pickle Objects/Shade Pickle Objects/' + movie + '.p'\n",
    "    shade = pickle.load(open(featurePath, \"rb\" )) \n",
    "    featurePath = 'Pickle Objects/Subtitle Sentiment Pickle Objects/' + movie + '.p'\n",
    "    sentiment = pickle.load(open(featurePath, \"rb\" )) \n",
    "    featurePath = 'Pickle Objects/ASL Pickle Objects/' + movie + '.p'\n",
    "    asl = pickle.load(open(featurePath, \"rb\" )) \n",
    "\n",
    "    runtime = int(movieRuntimeDf.loc[movieList.index(movie)]['effective runtime'])\n",
    "\n",
    "    colourDf = processVisuals(colour, runtime, True)\n",
    "    shadeDf = processVisuals(shade, runtime, False)\n",
    "    audioDf = processAudio(runtime, audio)\n",
    "    sentimentDf = processSubtitles(sentiment,runtime)\n",
    "    aslDf = processASL(asl, runtime)\n",
    "\n",
    "    #add windowing\n",
    "    effectiveRuntime = movieRuntimeDf['effective runtime'][movieList.index(movie)]\n",
    "    movieFeatureArray = np.array([])\n",
    "    for index in range(9, effectiveRuntime):\n",
    "        endIndex = index\n",
    "        startIndex = index - 9\n",
    "        colourWindow = colourDf.loc[startIndex:endIndex,:].values.ravel() #create 1D vector of values\n",
    "        audioWindow = audioDf.loc[startIndex:endIndex,:].values.ravel()\n",
    "        shadeWindow = shadeDf.loc[startIndex:endIndex,:].values.ravel()\n",
    "        sentimentWindow = sentimentDf.loc[startIndex:endIndex,:].values.ravel() \n",
    "        aslWindow = aslDf.loc[startIndex:endIndex,:].values.ravel()\n",
    "        window = np.concatenate([colourWindow, audioWindow, shadeWindow, sentimentWindow,aslWindow])\n",
    "        if len(movieFeatureArray) == 0:\n",
    "            movieFeatureArray = window\n",
    "        else:\n",
    "            movieFeatureArray = np.vstack([movieFeatureArray, window])\n",
    "\n",
    "    movieFeatureDict[movie] = pd.DataFrame(movieFeatureArray)\n",
    "\n",
    "print('Features Loaded')\n",
    "\n",
    "#import various numeric csvs\n",
    "vocPath = 'Numerical Data/2013VOCData.csv'\n",
    "voc2013DfAll = pd.read_csv(vocPath, header = 0, nrows = 74208, low_memory=False)\n",
    "movieScreeningsPath = 'Numerical Data/screening_times.csv'\n",
    "movingScreeningsDf = pd.read_csv(movieScreeningsPath, usecols = ['scheduled','movie','filled %'])\n",
    "movieRuntimesPath = 'Numerical Data/movie_runtimes.csv'\n",
    "movieRuntimeDf = pd.read_csv(movieRuntimesPath, usecols = ['movie', 'runtime (mins)', 'effective runtime'])\n",
    "#2015 Dataset\n",
    "starWarsPath = 'Numerical Data/Star Wars-The Force Awakens.csv'\n",
    "starWarsScreeningDf = pd.read_csv(starWarsPath)\n",
    "imOffThenPath = 'Numerical Data/I\\'m Off Then.csv'\n",
    "imOffThenScreeningDf = pd.read_csv(imOffThenPath)\n",
    "helpIShrunkTheTeacherPath = 'Numerical Data/Help, I Shrunk My Teacher.csv'\n",
    "helpIShrunkTheTeacherScreeningDf = pd.read_csv(helpIShrunkTheTeacherPath)\n",
    "vocPath = 'Numerical Data/2015VOCData.csv'\n",
    "voc2015DfAll = pd.read_csv(vocPath)\n",
    "#remove first column of 2015 voc df as its not used\n",
    "voc2015DfAll.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "#full list of movies\n",
    "movieList = list(movieRuntimeDf['movie'])\n",
    "\n",
    "\n",
    "#import the slicing indices\n",
    "slicePath = 'Pickle Objects/VocSlices.p'\n",
    "sliceDict = pickle.load(open(slicePath, \"rb\" )) #contains df of co2 slice indices and matched movie list\n",
    "\n",
    "#round the vocs\n",
    "voc2015Col = vocRounding(voc2015DfAll)\n",
    "voc2013Col = vocRounding(voc2013DfAll)\n",
    "voc2013Df = copy.deepcopy(voc2013DfAll)\n",
    "voc2015Df = copy.deepcopy(voc2015DfAll)\n",
    "voc2013Df.columns = voc2013Col\n",
    "voc2015Df.columns = voc2015Col\n",
    "\n",
    "#rearrange dataframe to be able to merge them successfully\n",
    "voc = voc2015Df.columns[1:]\n",
    "voc2015Df = pd.DataFrame(np.transpose(voc2015Df.values)[1:,:], columns =voc2015Df['Time'])\n",
    "voc2015Df['voc'] = voc\n",
    "voc = index=voc2013Df.columns[1:]\n",
    "voc2013Df = pd.DataFrame(np.transpose(voc2013Df.values)[1:,:], columns =voc2013Df['Time'])\n",
    "voc2013Df['voc'] = voc\n",
    "\n",
    "#join the two voc dataframes (join on the 2013 dataframe)\n",
    "vocDf = pd.merge(voc2013Df, voc2015Df, how='inner', on=['voc'])\n",
    "#drop voc column\n",
    "vocColumn = vocDf['voc']\n",
    "vocDf.drop(\"voc\", axis=1, inplace=True)\n",
    "\n",
    "#reorientate the vocDf, note need to convert all vocs to float\n",
    "vocDf = pd.DataFrame(np.transpose(vocDf.values.astype(float)), columns=vocColumn)\n",
    "print('Labels loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sof/.local/lib/python3.6/site-packages/ipykernel_launcher.py:157: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "resultsList = list()\n",
    "vocIndex = 0 #Choose CO2\n",
    "randomisationIterations = 30\n",
    "resultsHeader = ['RandomState','VOC','Precision', 'Accuracy']\n",
    "\n",
    "voc = vocDf.columns[vocIndex]\n",
    "vocData = vocDf[voc]\n",
    "\n",
    "print('Process Data')\n",
    "#generate normalised screenings\n",
    "screeningList, matchedMovies = generateNormalisedScreenings(sliceDict, vocData)\n",
    "\n",
    "#create input-output df\n",
    "featureLabelSet = inputOutputDf(screeningList,matchedMovies,movieFeatureDict)\n",
    "\n",
    "#extract labels and features\n",
    "features = featureLabelSet[:, 0:-1]\n",
    "labels = featureLabelSet[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run feature selection\n",
    "fs = ReliefF(n_neighbors=400, n_features_to_keep=2)\n",
    "fs.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(fs.top_features, open(\"fs_topfeatures_400,2.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3159, 3161, 3160, ...,    6,    3,    1])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot neighbours vs first 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create headers\n",
    "instancesPerWindow = 300\n",
    "colourHeader = list()\n",
    "for i in range(1,instancesPerWindow+1):\n",
    "    colourHeader = colourHeader + ['R'+str(i), 'G' + str(i),  'B'+str(i)]\n",
    "shadeHeader = ['S' + str(x) for x in range(1,instancesPerWindow+1)]\n",
    "audioHeader = list()\n",
    "for i in range(1,10+1):\n",
    "    audioWindowHeader = [x+'_'+str(i) for x in list(audioDf.columns)]\n",
    "    audioHeader = audioHeader + audioWindowHeader\n",
    "sentimentHeader = ['SV' + str(x) for x in range(1,11)]\n",
    "aslHeader = ['ASL' + str(x) for x in range(1,11)]\n",
    "arHeader = ['AR' + str(x) for x in range(1,10)]\n",
    "\n",
    "header = arHeader + colourHeader + audioHeader + shadeHeader + sentimentHeader + aslHeader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [x for x in listdir() if x[-1] == 'p' and x[-2] == '.' and x[0] == 'f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSelection = dict() #keys are the number of neighbours used, values are features ranking list\n",
    "for file in filenames:\n",
    "    \n",
    "    #load pickle file \n",
    "    featureRanking = pickle.load(open(file, \"rb\")) \n",
    "    noOfNeighbours = file[15:file.index(\",\")] #extract number of trees from the filename\n",
    "    featureSelection[int(noOfNeighbours)] = np.array(header)[featureRanking][0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbours  20\n",
      "['SV6' 'R109' 'B160' 'R23' 'G118' 'R200' 'SV4' 'R179' 'B130' 'SV1' 'SV2'\n",
      " 'S263' 'S77' 'S151' 'B39' 'B15' 'B190' 'R253' 'S238' 'S133' 'G148']\n",
      "\n",
      "Neighbours  30\n",
      "['SV6' 'SV2' 'SV8' 'SV1' 'SV4' 'SV3' 'R109' 'SV10' 'B160' 'B39' 'R23'\n",
      " 'G118' 'B159' 'B130' 'R200' 'R253' 'G148' 'ASL9' 'R229' 'ASL1' 'R172']\n",
      "\n",
      "Neighbours  50\n",
      "['SV1' 'SV2' 'SV9' 'SV4' 'SV8' 'SV3' 'SV6' 'SV5' 'SV10' 'SV7' 'ASL9'\n",
      " 'ASL7' 'ASL1' 'ASL10' 'R207' 'B130' 'B253' 'R143' 'ASL8' 'S110' 'R237']\n",
      "\n",
      "Neighbours  100\n",
      "['SV1' 'SV4' 'SV2' 'SV5' 'SV3' 'SV6' 'SV10' 'SV8' 'SV7' 'SV9' 'ASL1'\n",
      " 'ASL9' 'ASL7' 'ASL8' 'R207' 'ASL6' 'ASL4' 'R119' 'R209' 'R179' 'S107']\n",
      "\n",
      "Neighbours  150\n",
      "['SV4' 'SV1' 'SV2' 'SV3' 'SV5' 'SV6' 'SV7' 'SV8' 'SV10' 'SV9' 'ASL1'\n",
      " 'ASL7' 'ASL8' 'ASL9' 'ASL10' 'ASL3' 'ASL4' 'ASL6' 'R207' 'G164' 'R209']\n",
      "\n",
      "Neighbours  200\n",
      "['SV1' 'SV2' 'SV3' 'SV4' 'SV7' 'SV6' 'SV10' 'SV8' 'SV5' 'SV9' 'ASL1'\n",
      " 'ASL9' 'ASL8' 'ASL2' 'ASL7' 'ASL3' 'ASL4' 'ASL6' 'ASL10' 'ASL5' 'R179']\n",
      "\n",
      "Neighbours  250\n",
      "['SV1' 'SV2' 'SV3' 'SV4' 'SV6' 'SV7' 'SV5' 'SV8' 'SV10' 'SV9' 'ASL1'\n",
      " 'ASL9' 'ASL4' 'ASL8' 'ASL10' 'ASL7' 'ASL3' 'ASL6' 'tempo_1' 'ASL5' 'ASL2']\n",
      "\n",
      "Neighbours  400\n",
      "['SV1' 'SV3' 'SV2' 'SV4' 'SV5' 'SV7' 'SV6' 'SV8' 'SV9' 'SV10' 'ASL9'\n",
      " 'ASL8' 'ASL10' 'ASL1' 'ASL7' 'ASL4' 'ASL3' 'tempo_2' 'ASL5' 'ASL6' 'ASL2']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(featureSelection.keys()):\n",
    "    print('Neighbours ', i)\n",
    "    print(featureSelection[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 30, 50, 100, 150, 200, 250]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
